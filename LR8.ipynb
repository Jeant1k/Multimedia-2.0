{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Лабораторная работа №8: Проведение исследований с моделями обнаружения и распознавания объектов (Ultralytics YOLO)\n",
        "\n",
        "## 1. Выбор начальных условий\n",
        "\n",
        "### 1.a. Выбор набора данных и обоснование\n",
        "\n",
        "Для данной лабораторной работы был выбран набор данных **COCO128**. Это небольшой, но репрезентативный поднабор данных из известного датасета COCO (Common Objects in Context).\n",
        "\n",
        "**Обоснование выбора:**\n",
        "1.  **Доступность и простота использования:** COCO128 поставляется вместе с Ultralytics YOLO, что упрощает его загрузку и использование без необходимости ручной подготовки данных.\n",
        "2.  **Реальная практическая задача:** Обнаружение объектов на изображениях является фундаментальной задачей компьютерного зрения с множеством практических применений:\n",
        "    *   **Автономное вождение:** Обнаружение пешеходов, автомобилей, дорожных знаков.\n",
        "    *   **Видеонаблюдение и безопасность:** Идентификация подозрительных объектов или действий.\n",
        "    *   **Розничная торговля:** Анализ поведения покупателей, управление запасами (например, подсчет товаров на полках).\n",
        "    *   **Медицина:** Обнаружение аномалий на медицинских снимках (например, опухолей).\n",
        "    *   **Сельское хозяйство:** Мониторинг состояния посевов, подсчет скота.\n",
        "3.  **Разнообразие классов:** Несмотря на небольшой размер, COCO128 содержит изображения с объектами различных классов (80 классов из оригинального COCO), что позволяет обучать и тестировать модели на разнообразных сценариях.\n",
        "4.  **Подходит для демонстрации:** Малый размер датасета позволяет быстро проводить эксперименты, обучать модели и получать результаты в рамках лабораторной работы, не требуя значительных вычислительных ресурсов или времени.\n",
        "5.  **Стандартный формат аннотаций:** Данные представлены в формате YOLO, который является стандартом де-факто для многих моделей обнаружения объектов.\n",
        "\n",
        "Таким образом, COCO128 представляет собой удобный и релевантный датасет для изучения и экспериментирования с моделями обнаружения объектов семейства YOLO.\n",
        "\n",
        "### 1.b. Выбор метрик качества и обоснование\n",
        "\n",
        "Для оценки качества моделей обнаружения объектов будут использоваться следующие метрики:\n",
        "\n",
        "1.  **Precision (Точность):**\n",
        "    *   Формула: `Precision = TP / (TP + FP)`_\n",
        "    *   Описание: Доля правильно идентифицированных положительных объектов среди всех объектов, которые модель классифицировала как положительные. Отвечает на вопрос: \"Из всех объектов, которые модель назвала 'объектом X', сколько действительно являются 'объектом X'?\"\n",
        "    *   Обоснование: Важна, когда цена ложноположительных срабатываний высока (например, в системах безопасности, где ложная тревога может привести к ненужным действиям).\n",
        "\n",
        "2.  **Recall (Полнота):**\n",
        "    *   Формула: `Recall = TP / (TP + FN)`\n",
        "    *   Описание: Доля правильно идентифицированных положительных объектов среди всех реально существующих положительных объектов. Отвечает на вопрос: \"Сколько 'объектов X' из всех реально существующих 'объектов X' модель смогла найти?\"\n",
        "    *   Обоснование: Важна, когда цена ложноотрицательных срабатываний высока (например, в медицине, где пропуск заболевания может иметь серьезные последствия, или при поиске дефектов).\n",
        "\n",
        "3.  **mAP (mean Average Precision - средняя точность):**\n",
        "    *   **AP (Average Precision):** Площадь под кривой Precision-Recall для одного класса. AP вычисляется для каждого класса объектов отдельно.\n",
        "    *   **mAP@0.5 (или mAP50):** Среднее значение AP по всем классам, вычисленное при пороге IoU (Intersection over Union) равном 0.5. IoU измеряет степень пересечения между предсказанной ограничивающей рамкой и истинной рамкой. Порог 0.5 означает, что предсказание считается верным (TP), если IoU > 0.5.\n",
        "    *   **mAP@0.5:0.95 (или mAP):** Среднее значение AP по всем классам, вычисленное для различных порогов IoU (от 0.5 до 0.95 с шагом 0.05) и затем усредненное. Эта метрика более строгая и дает более комплексную оценку качества модели.\n",
        "\n",
        "    *   Обоснование: mAP является основной и наиболее комплексной метрикой для задач обнаружения объектов. Она учитывает как точность, так и полноту модели для каждого класса, а также качество локализации объектов (через IoU). mAP@0.5:0.95 дает наиболее объективную оценку общей производительности модели в различных условиях.\n",
        "\n",
        "**Выбор данных метрик обусловлен их широким распространением в области обнаружения объектов, способностью комплексно оценивать как классификационную, так и локализационную точность модели.**\n",
        "\n"
      ],
      "metadata": {
        "id": "nJqAMVeA-WfE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tA1PlPxw9kB-",
        "outputId": "771ddba8-c35e-433a-cb9b-b21b21d6e350"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m125.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Установка Ultralytics\n",
        "!pip install ultralytics -q\n",
        "!pip install roboflow -q # На всякий случай, если понадобится для другого датасета\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ultralytics\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import yaml # Для работы с YAML файлами датасета\n",
        "\n",
        "# Проверка установки\n",
        "ultralytics.checks()\n",
        "\n",
        "# Глобальные переменные для хранения результатов\n",
        "results_history = {}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgEOLv5Q-mhv",
        "outputId": "1ac6e199-be3d-4f8b-9b71-96935f753e00"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.139 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 41.5/112.6 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Создание бейзлайна и оценка качества\n",
        "\n",
        "На этом этапе мы обучим одну из стандартных моделей YOLO (например, YOLOv8n - nano, самую маленькую и быструю) на нашем наборе данных `coco128.yaml` с базовыми настройками. Это будет наш бейзлайн.\n",
        "\n",
        "### 2.a. Обучение \"коробочной\" модели YOLO из Ultralytics\n",
        "Будем использовать YOLOv8n (nano) как самую быструю для демонстрации\n",
        "epochs можно поставить поменьше для скорости, например 10-25 для лабораторной\n",
        "Для реальных задач нужно больше, например, 100-300.\n",
        "imgsz - размер изображений, на которых обучается модель\n"
      ],
      "metadata": {
        "id": "CC-xzwyr-p6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Задаем параметры\n",
        "dataset_yaml = 'coco128.yaml' # Стандартный датасет Ultralytics, загрузится автоматически\n",
        "baseline_model_name = 'yolov8n.pt' # Используем предварительно обученную модель yolov8n\n",
        "baseline_epochs = 25 # Уменьшим для скорости выполнения лабораторной\n",
        "baseline_imgsz = 640\n",
        "baseline_project_name = 'coco128_baseline'\n",
        "baseline_experiment_name = 'yolov8n_baseline_run'\n",
        "\n",
        "print(f\"Обучение бейзлайн модели: {baseline_model_name}\")\n",
        "print(f\"Датасет: {dataset_yaml}\")\n",
        "print(f\"Количество эпох: {baseline_epochs}\")\n",
        "print(f\"Размер изображения: {baseline_imgsz}\")\n",
        "\n",
        "# Создаем модель\n",
        "model_baseline = YOLO(baseline_model_name)\n",
        "\n",
        "# Обучение модели\n",
        "# device=0 означает использование первого доступного GPU, если есть, иначе CPU.\n",
        "# В Colab это обычно GPU Tesla T4, K80 и т.д.\n",
        "try:\n",
        "    history_baseline = model_baseline.train(\n",
        "        data=dataset_yaml,\n",
        "        epochs=baseline_epochs,\n",
        "        imgsz=baseline_imgsz,\n",
        "        project=baseline_project_name,\n",
        "        name=baseline_experiment_name,\n",
        "        exist_ok=True, # Перезаписывать, если эксперимент уже существует\n",
        "        patience=5 # Ранняя остановка, если нет улучшений в течение 5 эпох\n",
        "    )\n",
        "    print(\"Обучение бейзлайн модели завершено.\")\n",
        "    baseline_weights_path = os.path.join(baseline_project_name, baseline_experiment_name, 'weights', 'best.pt')\n",
        "    print(f\"Лучшие веса сохранены в: {baseline_weights_path}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка во время обучения бейзлайн модели: {e}\")\n",
        "    # В случае ошибки (например, нет GPU или битая установка)\n",
        "    # можно попробовать device='cpu' или уменьшить batch size (batch=-1 для автоподбора)\n",
        "    # history_baseline = model_baseline.train(data=dataset_yaml, epochs=baseline_epochs, imgsz=baseline_imgsz, device='cpu', batch=8) # Пример для CPU\n",
        "    history_baseline = None # или какое-то значение по умолчанию/обработка\n",
        "    baseline_weights_path = None\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "996N4n-V-tTq",
        "outputId": "c2813341-53a7-44b3-c069-181ed543e8a8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обучение бейзлайн модели: yolov8n.pt\n",
            "Датасет: coco128.yaml\n",
            "Количество эпох: 25\n",
            "Размер изображения: 640\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.25M/6.25M [00:00<00:00, 107MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.139 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=coco128.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=25, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8n_baseline_run, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=5, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=coco128_baseline, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=coco128_baseline/yolov8n_baseline_run, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "WARNING ⚠️ Dataset 'coco128.yaml' images not found, missing path '/content/datasets/coco128/images/train2017'\n",
            "Downloading https://ultralytics.com/assets/coco128.zip to '/content/datasets/coco128.zip'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.66M/6.66M [00:00<00:00, 108MB/s]\n",
            "Unzipping /content/datasets/coco128.zip to /content/datasets/coco128...: 100%|██████████| 263/263 [00:00<00:00, 3420.39file/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset download success ✅ (0.8s), saved to \u001b[1m/content/datasets\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 22.0MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model summary: 129 layers, 3,157,200 parameters, 3,157,184 gradients, 8.9 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.35M/5.35M [00:00<00:00, 83.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 788.6±469.6 MB/s, size: 50.9 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco128/labels/train2017... 126 images, 2 backgrounds, 0 corrupt: 100%|██████████| 128/128 [00:00<00:00, 2643.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/coco128/labels/train2017.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 526.9±110.5 MB/s, size: 52.5 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|██████████| 128/128 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to coco128_baseline/yolov8n_baseline_run/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mcoco128_baseline/yolov8n_baseline_run\u001b[0m\n",
            "Starting training for 25 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/25       2.6G      1.156      1.519      1.226        172        640: 100%|██████████| 8/8 [00:03<00:00,  2.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.649      0.536      0.613      0.454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/25      3.53G      1.209      1.436      1.243        231        640: 100%|██████████| 8/8 [00:02<00:00,  3.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.651      0.558      0.629      0.472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/25      3.56G       1.16      1.366      1.252        192        640: 100%|██████████| 8/8 [00:01<00:00,  4.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.647       0.59      0.647      0.483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/25      3.57G      1.164       1.31      1.227        215        640: 100%|██████████| 8/8 [00:02<00:00,  3.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.672      0.577      0.656       0.49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/25      3.58G      1.187      1.312      1.263        236        640: 100%|██████████| 8/8 [00:01<00:00,  4.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  4.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.693      0.581      0.673      0.504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/25      3.59G      1.182      1.287      1.229        253        640: 100%|██████████| 8/8 [00:02<00:00,  2.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.667      0.624      0.686      0.518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/25      3.59G      1.084      1.204      1.195        282        640: 100%|██████████| 8/8 [00:01<00:00,  4.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  4.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.689      0.635      0.694      0.524\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/25      3.59G      1.123      1.204      1.203        192        640: 100%|██████████| 8/8 [00:01<00:00,  4.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  4.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.738      0.642      0.714      0.542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/25      3.59G      1.105      1.107      1.187        180        640: 100%|██████████| 8/8 [00:01<00:00,  4.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.704      0.657      0.722      0.554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/25      3.59G      1.065      1.121      1.155        180        640: 100%|██████████| 8/8 [00:01<00:00,  4.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.745      0.644      0.727      0.559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/25      3.59G      1.078        1.1      1.171        263        640: 100%|██████████| 8/8 [00:01<00:00,  4.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.771      0.653       0.74      0.568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/25      3.61G      1.099      1.135      1.179        176        640: 100%|██████████| 8/8 [00:01<00:00,  4.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929       0.79      0.651      0.749      0.575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/25      3.61G      1.095      1.085       1.18        251        640: 100%|██████████| 8/8 [00:01<00:00,  4.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.812       0.65      0.761      0.583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/25      3.63G      1.033       1.05      1.153        208        640: 100%|██████████| 8/8 [00:01<00:00,  4.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  4.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.827      0.654      0.768      0.589\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/25      3.63G      1.044      1.045       1.14        251        640: 100%|██████████| 8/8 [00:02<00:00,  3.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.805      0.677      0.772      0.589\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/25      3.63G      1.112      1.138      1.152         95        640: 100%|██████████| 8/8 [00:02<00:00,  2.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.811      0.676      0.775       0.59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/25      3.63G      1.099      1.099      1.151        104        640: 100%|██████████| 8/8 [00:02<00:00,  3.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929       0.79      0.693      0.777      0.591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/25      3.63G      1.036      1.053       1.15        102        640: 100%|██████████| 8/8 [00:01<00:00,  4.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  4.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.778      0.701      0.778      0.594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/25      3.63G      1.064      1.031      1.127        139        640: 100%|██████████| 8/8 [00:01<00:00,  4.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.756      0.713      0.781      0.596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/25      3.63G      1.021     0.9981      1.115         94        640: 100%|██████████| 8/8 [00:01<00:00,  4.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.757      0.708      0.781      0.598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/25      3.63G      1.079      1.029      1.157        127        640: 100%|██████████| 8/8 [00:01<00:00,  4.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929       0.75      0.711      0.783      0.599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/25      3.63G      1.027     0.9785      1.115         79        640: 100%|██████████| 8/8 [00:01<00:00,  4.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  4.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.735      0.723      0.783      0.599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/25      3.63G      1.061     0.9803      1.113         99        640: 100%|██████████| 8/8 [00:01<00:00,  4.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  4.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.734      0.739      0.785      0.603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/25      3.63G      1.032     0.9629      1.123        118        640: 100%|██████████| 8/8 [00:01<00:00,  4.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.729      0.742      0.787      0.604\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/25      3.63G      1.049     0.9869      1.117        133        640: 100%|██████████| 8/8 [00:01<00:00,  4.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.714      0.742      0.785      0.602\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "25 epochs completed in 0.025 hours.\n",
            "Optimizer stripped from coco128_baseline/yolov8n_baseline_run/weights/last.pt, 6.5MB\n",
            "Optimizer stripped from coco128_baseline/yolov8n_baseline_run/weights/best.pt, 6.5MB\n",
            "\n",
            "Validating coco128_baseline/yolov8n_baseline_run/weights/best.pt...\n",
            "Ultralytics 8.3.139 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.724       0.74      0.786      0.602\n",
            "                person         61        254       0.87      0.686      0.808      0.601\n",
            "               bicycle          3          6      0.726      0.333      0.512      0.401\n",
            "                   car         12         46      0.621      0.261      0.412      0.236\n",
            "            motorcycle          4          5      0.768        0.8      0.938      0.787\n",
            "              airplane          5          6      0.781          1      0.948      0.881\n",
            "                   bus          5          7      0.786      0.714      0.723      0.652\n",
            "                 train          3          3      0.575          1      0.995      0.886\n",
            "                 truck          5         12      0.822        0.5      0.592      0.413\n",
            "                  boat          2          6      0.636      0.667      0.636      0.396\n",
            "         traffic light          4         14      0.542      0.143      0.205      0.151\n",
            "             stop sign          2          2      0.705          1      0.995      0.746\n",
            "                 bench          5          9      0.847      0.889      0.918      0.698\n",
            "                  bird          2         16      0.941      0.996      0.991      0.708\n",
            "                   cat          4          4       0.69          1      0.895      0.794\n",
            "                   dog          9          9      0.833      0.889      0.968      0.786\n",
            "                 horse          1          2       0.74          1      0.995      0.697\n",
            "              elephant          4         17      0.924      0.941      0.972      0.777\n",
            "                  bear          1          1      0.621          1      0.995      0.995\n",
            "                 zebra          2          4      0.861          1      0.995      0.974\n",
            "               giraffe          4          9      0.901          1      0.995      0.721\n",
            "              backpack          4          6      0.559      0.333      0.498      0.306\n",
            "              umbrella          4         18      0.711      0.778      0.839      0.575\n",
            "               handbag          9         19      0.727      0.368      0.507      0.237\n",
            "                   tie          6          7      0.822      0.857      0.817      0.637\n",
            "              suitcase          2          4      0.693          1      0.945      0.617\n",
            "               frisbee          5          5      0.762        0.8      0.799      0.709\n",
            "                  skis          1          1       0.83          1      0.995      0.497\n",
            "             snowboard          2          7      0.514       0.91       0.86       0.64\n",
            "           sports ball          6          6          1      0.422      0.636      0.393\n",
            "                  kite          2         10      0.481        0.5      0.618      0.222\n",
            "          baseball bat          4          4      0.594       0.25      0.428      0.295\n",
            "        baseball glove          4          7      0.949      0.429      0.434      0.305\n",
            "            skateboard          3          5      0.729        0.6      0.658      0.485\n",
            "         tennis racket          5          7      0.505      0.429      0.591      0.347\n",
            "                bottle          6         18      0.626      0.373      0.535      0.323\n",
            "            wine glass          5         16       0.41       0.75      0.717      0.416\n",
            "                   cup         10         36      0.808      0.467      0.643      0.457\n",
            "                  fork          6          6          1      0.316      0.565      0.405\n",
            "                 knife          7         16      0.721      0.625      0.683      0.438\n",
            "                 spoon          5         22      0.437      0.455      0.504      0.338\n",
            "                  bowl          9         28      0.829      0.821      0.856      0.712\n",
            "                banana          1          1      0.615          1      0.995      0.796\n",
            "              sandwich          2          2      0.577          1      0.995      0.995\n",
            "                orange          1          4      0.575          1      0.995      0.647\n",
            "              broccoli          4         11      0.525      0.364      0.485      0.347\n",
            "                carrot          3         24        0.8      0.833      0.872       0.56\n",
            "               hot dog          1          2      0.749          1      0.995      0.995\n",
            "                 pizza          5          5      0.834          1      0.995       0.89\n",
            "                 donut          2         14      0.618          1       0.97      0.892\n",
            "                  cake          4          4      0.847          1      0.995      0.952\n",
            "                 chair          9         35      0.628      0.676      0.684      0.455\n",
            "                 couch          5          6      0.697      0.833      0.931      0.717\n",
            "          potted plant          9         14      0.759      0.786      0.848      0.648\n",
            "                   bed          3          3       0.77          1      0.995       0.83\n",
            "          dining table         10         13      0.665      0.692      0.726      0.595\n",
            "                toilet          2          2      0.718          1      0.995      0.946\n",
            "                    tv          2          2      0.701          1      0.995      0.847\n",
            "                laptop          2          3      0.836          1      0.995      0.897\n",
            "                 mouse          2          2          1          0      0.251      0.226\n",
            "                remote          5          8      0.887      0.625      0.718      0.593\n",
            "            cell phone          5          8      0.222      0.125        0.2      0.166\n",
            "             microwave          3          3      0.724          1      0.995      0.817\n",
            "                  oven          5          5      0.767        0.6        0.6       0.44\n",
            "                  sink          4          6      0.571      0.665       0.64       0.43\n",
            "          refrigerator          5          5      0.823        0.8      0.962      0.807\n",
            "                  book          6         29      0.574      0.465      0.577      0.331\n",
            "                 clock          8          9      0.864      0.889      0.908      0.802\n",
            "                  vase          2          2      0.682          1      0.995      0.945\n",
            "              scissors          1          1      0.916          1      0.995       0.25\n",
            "            teddy bear          6         21      0.729      0.857      0.884      0.623\n",
            "            toothbrush          2          5      0.839          1      0.995      0.678\n",
            "Speed: 0.3ms preprocess, 3.6ms inference, 0.0ms loss, 4.2ms postprocess per image\n",
            "Results saved to \u001b[1mcoco128_baseline/yolov8n_baseline_run\u001b[0m\n",
            "Обучение бейзлайн модели завершено.\n",
            "Лучшие веса сохранены в: coco128_baseline/yolov8n_baseline_run/weights/best.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.b. Оценка качества модели (бейзлайн) по выбранным метрикам\n",
        "Оценка будет проводиться на валидационном наборе данных, указанном в coco128.yaml\n"
      ],
      "metadata": {
        "id": "bi5B_ZB8-6S1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " if baseline_weights_path and os.path.exists(baseline_weights_path):\n",
        "    print(f\"Оценка бейзлайн модели с весами: {baseline_weights_path}\")\n",
        "    # Загружаем лучшую модель, полученную после обучения\n",
        "    model_eval_baseline = YOLO(baseline_weights_path)\n",
        "\n",
        "    # Проводим оценку (валидацию)\n",
        "    # split='val' по умолчанию, verbose=True для вывода метрик по классам\n",
        "    metrics_baseline = model_eval_baseline.val(\n",
        "        data=dataset_yaml,\n",
        "        imgsz=baseline_imgsz,\n",
        "        split='val',\n",
        "        project=baseline_project_name,\n",
        "        name=baseline_experiment_name + \"_eval\",\n",
        "        exist_ok=True\n",
        "    )\n",
        "    print(\"\\nРезультаты оценки бейзлайн модели:\")\n",
        "    if metrics_baseline:\n",
        "      print(f\"  Precision(B): {metrics_baseline.box.mp:.4f}\") # mP средняя точность по всем классам\n",
        "      print(f\"  Recall(B): {metrics_baseline.box.mr:.4f}\")    # mR средняя полнота по всем классам\n",
        "      print(f\"  mAP50(B): {metrics_baseline.box.map50:.4f}\")\n",
        "      print(f\"  mAP50-95(B): {metrics_baseline.box.map:.4f}\") # Основная метрика mAP\n",
        "\n",
        "      results_history['baseline'] = {\n",
        "          'model': baseline_model_name.split('.')[0],\n",
        "          'weights': baseline_weights_path,\n",
        "          'precision': metrics_baseline.box.mp,\n",
        "          'recall': metrics_baseline.box.mr,\n",
        "          'mAP50': metrics_baseline.box.map50,\n",
        "          'mAP50-95': metrics_baseline.box.map\n",
        "      }\n",
        "    else:\n",
        "        print(\"Не удалось получить метрики для бейзлайн модели.\")\n",
        "        results_history['baseline'] = {\n",
        "          'model': baseline_model_name.split('.')[0],\n",
        "          'weights': \"N/A\",\n",
        "          'precision': 0, 'recall': 0, 'mAP50': 0, 'mAP50-95': 0\n",
        "        }\n",
        "\n",
        "    # Показать примеры предсказаний\n",
        "    # val_results_path = os.path.join(baseline_project_name, baseline_experiment_name + \"_eval\")\n",
        "    # print(f\"Результаты валидации (изображения с рамками) сохранены в: {val_results_path}\")\n",
        "    # # Показать первые несколько изображений с предсказаниями (если они были сохранены)\n",
        "    # pred_images = [os.path.join(val_results_path, img) for img in os.listdir(val_results_path) if img.endswith(('.png', '.jpg', '.jpeg'))][:3]\n",
        "    # for img_path in pred_images:\n",
        "    #     plt.figure(figsize=(8,8))\n",
        "    #     plt.imshow(cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB))\n",
        "    #     plt.title(os.path.basename(img_path))\n",
        "    #     plt.axis('off')\n",
        "    #     plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"Файл с весами бейзлайн модели не найден. Оценка невозможна.\")\n",
        "    results_history['baseline'] = {\n",
        "          'model': baseline_model_name.split('.')[0],\n",
        "          'weights': \"N/A\",\n",
        "          'precision': 0, 'recall': 0, 'mAP50': 0, 'mAP50-95': 0\n",
        "    }\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HzVAski-6fD",
        "outputId": "c51d576b-ad37-4ac8-b196-cf0c64ef5363"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Оценка бейзлайн модели с весами: coco128_baseline/yolov8n_baseline_run/weights/best.pt\n",
            "Ultralytics 8.3.139 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1041.3±367.7 MB/s, size: 53.4 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|██████████| 128/128 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  2.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.763      0.728      0.786      0.605\n",
            "                person         61        254      0.899      0.669      0.811      0.601\n",
            "               bicycle          3          6      0.754      0.333      0.542      0.431\n",
            "                   car         12         46      0.792      0.261      0.434       0.24\n",
            "            motorcycle          4          5      0.802        0.8      0.938      0.787\n",
            "              airplane          5          6      0.794          1      0.948      0.882\n",
            "                   bus          5          7      0.806      0.714      0.723      0.673\n",
            "                 train          3          3      0.592          1      0.995      0.886\n",
            "                 truck          5         12      0.861        0.5      0.581      0.414\n",
            "                  boat          2          6      0.745       0.49      0.648      0.405\n",
            "         traffic light          4         14      0.563      0.143      0.206      0.151\n",
            "             stop sign          2          2      0.731          1      0.995      0.746\n",
            "                 bench          5          9      0.883      0.842       0.92       0.72\n",
            "                  bird          2         16      0.939      0.966      0.991      0.716\n",
            "                   cat          4          4      0.697          1      0.945      0.842\n",
            "                   dog          9          9      0.842      0.889      0.968      0.794\n",
            "                 horse          1          2       0.76          1      0.995      0.697\n",
            "              elephant          4         17      0.948      0.941      0.972      0.777\n",
            "                  bear          1          1       0.64          1      0.995      0.995\n",
            "                 zebra          2          4      0.868          1      0.995      0.976\n",
            "               giraffe          4          9      0.913          1      0.995      0.748\n",
            "              backpack          4          6      0.578      0.333      0.546      0.338\n",
            "              umbrella          4         18      0.749      0.662      0.839      0.577\n",
            "               handbag          9         19      0.776      0.368      0.515       0.23\n",
            "                   tie          6          7      0.842      0.857      0.817      0.637\n",
            "              suitcase          2          4      0.725          1      0.945      0.618\n",
            "               frisbee          5          5      0.784        0.8      0.799      0.709\n",
            "                  skis          1          1      0.795          1      0.995      0.547\n",
            "             snowboard          2          7      0.519      0.857       0.86      0.641\n",
            "           sports ball          6          6          1      0.389       0.67       0.42\n",
            "                  kite          2         10      0.605        0.4      0.538       0.23\n",
            "          baseball bat          4          4          1      0.436      0.513      0.317\n",
            "        baseball glove          4          7      0.982      0.429      0.434       0.32\n",
            "            skateboard          3          5      0.808        0.6      0.653      0.483\n",
            "         tennis racket          5          7      0.528      0.429      0.567      0.354\n",
            "                bottle          6         18      0.593      0.324      0.508      0.333\n",
            "            wine glass          5         16      0.585       0.75       0.73       0.43\n",
            "                   cup         10         36      0.849      0.468      0.641      0.467\n",
            "                  fork          6          6          1      0.308      0.512      0.362\n",
            "                 knife          7         16       0.78      0.625      0.684      0.445\n",
            "                 spoon          5         22      0.503      0.455      0.517      0.352\n",
            "                  bowl          9         28      0.852      0.819      0.857       0.72\n",
            "                banana          1          1      0.639          1      0.995      0.796\n",
            "              sandwich          2          2      0.616          1      0.995      0.995\n",
            "                orange          1          4      0.589          1      0.995      0.647\n",
            "              broccoli          4         11      0.572      0.364      0.485      0.348\n",
            "                carrot          3         24      0.824      0.833      0.883      0.559\n",
            "               hot dog          1          2      0.763          1      0.995      0.995\n",
            "                 pizza          5          5      0.848          1      0.995      0.883\n",
            "                 donut          2         14      0.604          1      0.973      0.881\n",
            "                  cake          4          4      0.847          1      0.995      0.952\n",
            "                 chair          9         35      0.573      0.575      0.655      0.444\n",
            "                 couch          5          6      0.808      0.833      0.904      0.704\n",
            "          potted plant          9         14      0.798      0.786      0.841      0.669\n",
            "                   bed          3          3      0.803          1      0.995       0.83\n",
            "          dining table         10         13      0.787      0.692      0.727      0.591\n",
            "                toilet          2          2      0.733          1      0.995      0.946\n",
            "                    tv          2          2       0.72          1      0.995      0.847\n",
            "                laptop          2          3      0.838          1      0.995      0.864\n",
            "                 mouse          2          2          1          0     0.0654     0.0523\n",
            "                remote          5          8          1      0.683      0.748      0.611\n",
            "            cell phone          5          8      0.277      0.125      0.235      0.169\n",
            "             microwave          3          3      0.754          1      0.995      0.817\n",
            "                  oven          5          5       0.79        0.6        0.6      0.467\n",
            "                  sink          4          6      0.505      0.511       0.64       0.43\n",
            "          refrigerator          5          5      0.838        0.8      0.962      0.807\n",
            "                  book          6         29       0.65      0.321      0.591      0.363\n",
            "                 clock          8          9      0.889      0.889      0.909      0.812\n",
            "                  vase          2          2      0.718          1      0.995      0.945\n",
            "              scissors          1          1      0.978          1      0.995       0.25\n",
            "            teddy bear          6         21      0.824       0.81      0.905      0.607\n",
            "            toothbrush          2          5      0.907          1      0.995      0.644\n",
            "Speed: 1.6ms preprocess, 7.1ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
            "Results saved to \u001b[1mcoco128_baseline/yolov8n_baseline_run_eval\u001b[0m\n",
            "\n",
            "Результаты оценки бейзлайн модели:\n",
            "  Precision(B): 0.7630\n",
            "  Recall(B): 0.7279\n",
            "  mAP50(B): 0.7858\n",
            "  mAP50-95(B): 0.6047\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Улучшение бейзлайна\n",
        "\n",
        "На этом этапе мы попытаемся улучшить результаты бейзлайн-модели.\n",
        "\n",
        "### 3.a. Формулирование гипотез\n",
        "1.  **Увеличение количества эпох обучения:** Большее количество эпох может позволить модели лучше настроиться на данные.\n",
        "2.  **Использование более \"тяжелой\" модели:** Модели с большим количеством параметров (например, `yolov8s.pt` - small) могут показать лучшее качество за счет большей выразительной способности, но будут обучаться дольше и требовать больше ресурсов.\n",
        "3.  **Оптимизация гиперпараметров:** Изменение скорости обучения (`lr0`), оптимизатора, или параметров аугментации. Ultralytics YOLO автоматически применяет сильные аугментации, но их можно тонко настроить (например, `degrees`, `translate`, `scale`, `fliplr`, `mosaic`, `mixup`).\n",
        "4.  **Увеличение размера входного изображения (`imgsz`):** Модели могут лучше распознавать мелкие объекты при большем разрешении, но это увеличивает вычислительную нагрузку.\n",
        "\n",
        "**Проверяемые гипотезы в рамках данной работы:**\n",
        "*   **Гипотеза 1:** Увеличение количества эпох обучения (с `baseline_epochs` до `improved_epochs`) улучшит метрики.\n",
        "*   **Гипотеза 2:** Использование более крупной модели (`yolov8s.pt` вместо `yolov8n.pt`) при том же (или немного увеличенном) количестве эпох улучшит метрики.\n",
        "*   **Гипотеза 3 (Комбинированная):** Использование более крупной модели (`yolov8s.pt`) И большего числа эпох (`improved_epochs`) И, возможно, других гиперпараметров (например, изменение `lr0` или включение/отключение `mosaic` аугментации) даст наилучший результат.\n",
        "\n",
        "Для улучшения бейзлайна выберем **Гипотезу 3** как наиболее перспективную: используем модель `yolov8s.pt`, увеличим количество эпох и, возможно, слегка скорректируем некоторые параметры обучения, если потребуется (но для начала оставим параметры по умолчанию, кроме модели и эпох).\n",
        "\n",
        "### 3.b. Проверка гипотез (в данном случае, сразу формируем улучшенный бейзлайн)\n",
        "\n",
        "Cогласно выбранной гипотезе, пробуем yolov8s и больше эпох\n"
      ],
      "metadata": {
        "id": "TfomhW6c_XR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "improved_model_name = 'yolov8s.pt' # Берем модель побольше\n",
        "improved_epochs = baseline_epochs + 15 # Увеличиваем количество эпох (например, до 40)\n",
        "improved_imgsz = baseline_imgsz # Оставим тот же размер изображения для сравнения\n",
        "improved_project_name = 'coco128_improved'\n",
        "improved_experiment_name = 'yolov8s_improved_run'\n",
        "\n",
        "# Мы можем также попробовать изменить learning rate или другие параметры\n",
        "# Например: lr0=0.001 (стандартное 0.01), optimizer='AdamW' (стандартное SGD или Adam)\n",
        "# Для демонстрации оставим большинство параметров по умолчанию для yolov8s\n",
        "# Можно добавить/изменить параметры аугментации, например:\n",
        "# augment_params = {'degrees': 10, 'translate': 0.15, 'scale': 0.6, 'fliplr': 0.5, 'mosaic': 0.5, 'mixup':0.1}\n",
        "# и передать их в model.train(**augment_params)\n",
        "\n",
        "print(f\"Обучение улучшенной модели: {improved_model_name}\")\n",
        "print(f\"Датасет: {dataset_yaml}\")\n",
        "print(f\"Количество эпох: {improved_epochs}\")\n",
        "print(f\"Размер изображения: {improved_imgsz}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ucXMfWa_erx",
        "outputId": "4e3ee624-6aac-40de-bb7d-69ab7318ae14"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обучение улучшенной модели: yolov8s.pt\n",
            "Датасет: coco128.yaml\n",
            "Количество эпох: 40\n",
            "Размер изображения: 640\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.c. Формирование улучшенного бейзлайна\n",
        "Это уже сделано выбором модели и параметров выше.\n",
        "\n",
        "### 3.d. Обучение модели с улучшенным бейзлайном\n"
      ],
      "metadata": {
        "id": "2AijtNoX_mG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_improved = YOLO(improved_model_name)\n",
        "\n",
        "try:\n",
        "    history_improved = model_improved.train(\n",
        "        data=dataset_yaml,\n",
        "        epochs=improved_epochs,\n",
        "        imgsz=improved_imgsz,\n",
        "        project=improved_project_name,\n",
        "        name=improved_experiment_name,\n",
        "        exist_ok=True,\n",
        "        patience=10 # Можно увеличить patience для более \"тяжелой\" модели\n",
        "        # lr0=0.005, # Пример изменения learning rate\n",
        "        # mosaic=0.8, # Пример изменения параметра аугментации\n",
        "    )\n",
        "    print(\"Обучение улучшенной модели завершено.\")\n",
        "    improved_weights_path = os.path.join(improved_project_name, improved_experiment_name, 'weights', 'best.pt')\n",
        "    print(f\"Лучшие веса сохранены в: {improved_weights_path}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка во время обучения улучшенной модели: {e}\")\n",
        "    history_improved = None\n",
        "    improved_weights_path = None\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f0AujCD_qok",
        "outputId": "127a01b3-e274-4a8d-e2e1-95a0964f827e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21.5M/21.5M [00:00<00:00, 107MB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.139 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=coco128.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=40, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8s_improved_run, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=coco128_improved, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=coco128_improved/yolov8s_improved_run, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2147008  ultralytics.nn.modules.head.Detect           [80, [128, 256, 512]]         \n",
            "Model summary: 129 layers, 11,166,560 parameters, 11,166,544 gradients, 28.8 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1212.8±579.2 MB/s, size: 50.9 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|██████████| 128/128 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 399.3±86.5 MB/s, size: 52.5 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|██████████| 128/128 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to coco128_improved/yolov8s_improved_run/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mcoco128_improved/yolov8s_improved_run\u001b[0m\n",
            "Starting training for 40 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/40      3.99G       1.04      1.095      1.182        172        640: 100%|██████████| 8/8 [00:03<00:00,  2.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.814      0.675      0.773      0.598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/40      4.98G      1.073      1.071      1.181        231        640: 100%|██████████| 8/8 [00:02<00:00,  3.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.804      0.699      0.788      0.614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/40      4.99G      1.027      1.015      1.193        192        640: 100%|██████████| 8/8 [00:02<00:00,  2.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.795      0.714      0.791      0.615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/40      4.99G       1.04     0.9511      1.161        215        640: 100%|██████████| 8/8 [00:02<00:00,  3.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.778      0.736        0.8       0.62\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/40      5.03G      1.033     0.9415      1.164        236        640: 100%|██████████| 8/8 [00:02<00:00,  3.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929       0.76      0.746      0.808      0.632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/40      5.03G      1.019     0.9308      1.142        253        640: 100%|██████████| 8/8 [00:02<00:00,  2.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.797      0.751      0.822       0.65\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/40      5.03G     0.9578     0.8358      1.122        282        640: 100%|██████████| 8/8 [00:02<00:00,  3.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.814       0.75      0.832      0.657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/40      5.06G     0.9678     0.8509      1.114        192        640: 100%|██████████| 8/8 [00:02<00:00,  3.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.816      0.765      0.834      0.664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/40      5.06G     0.9502     0.7919      1.096        180        640: 100%|██████████| 8/8 [00:03<00:00,  2.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.814      0.773      0.838      0.671\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/40      5.06G     0.9012     0.7908      1.063        180        640: 100%|██████████| 8/8 [00:02<00:00,  3.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.828      0.791      0.857      0.675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/40      5.06G       0.91     0.7581      1.083        263        640: 100%|██████████| 8/8 [00:02<00:00,  3.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.841      0.797      0.864      0.687\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/40      5.06G     0.9488     0.7832      1.093        176        640: 100%|██████████| 8/8 [00:02<00:00,  2.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.858      0.801      0.868      0.694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/40      5.06G      0.906     0.7381      1.085        251        640: 100%|██████████| 8/8 [00:02<00:00,  3.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.869      0.798      0.866        0.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/40      5.06G     0.8488     0.7117      1.058        208        640: 100%|██████████| 8/8 [00:02<00:00,  3.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.888      0.789      0.871      0.705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/40      5.06G     0.8767     0.7021      1.044        251        640: 100%|██████████| 8/8 [00:02<00:00,  2.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.885       0.79      0.872      0.713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/40       5.1G     0.9315     0.7448       1.07        189        640: 100%|██████████| 8/8 [00:02<00:00,  3.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.857      0.814      0.873      0.716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/40       5.1G      0.879      0.739      1.064        184        640: 100%|██████████| 8/8 [00:02<00:00,  3.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.908      0.793      0.878      0.724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/40      5.13G     0.8469     0.6685      1.031        208        640: 100%|██████████| 8/8 [00:02<00:00,  2.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.914        0.8      0.883      0.726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/40      5.13G     0.8749     0.6777       1.05        169        640: 100%|██████████| 8/8 [00:02<00:00,  3.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.908      0.813      0.885      0.735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/40      5.17G     0.8322     0.6717      1.037        185        640: 100%|██████████| 8/8 [00:02<00:00,  3.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.911      0.814      0.887      0.737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/40      5.17G      0.822     0.6413      1.026        317        640: 100%|██████████| 8/8 [00:02<00:00,  2.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.911      0.817       0.89      0.742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/40      5.17G     0.8208     0.6457      1.022        255        640: 100%|██████████| 8/8 [00:02<00:00,  3.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.907      0.823      0.894      0.744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/40      5.21G     0.8537     0.6738      1.032        227        640: 100%|██████████| 8/8 [00:02<00:00,  3.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.906      0.829      0.897      0.747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/40      5.21G     0.8029     0.6323      1.027        196        640: 100%|██████████| 8/8 [00:02<00:00,  3.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.905      0.833      0.897       0.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/40      5.24G     0.8083     0.6218      1.015        244        640: 100%|██████████| 8/8 [00:02<00:00,  3.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.916      0.832      0.898      0.754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/40      5.24G     0.8191     0.6223      1.027        228        640: 100%|██████████| 8/8 [00:02<00:00,  3.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.916      0.833      0.902      0.755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/40      5.24G     0.7912     0.6056       1.01        202        640: 100%|██████████| 8/8 [00:02<00:00,  3.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.924      0.833      0.905      0.757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/40      5.24G     0.7899     0.6164      1.025        229        640: 100%|██████████| 8/8 [00:02<00:00,  3.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.924      0.839      0.907      0.761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/40      5.24G     0.7972      0.613      1.024        169        640: 100%|██████████| 8/8 [00:02<00:00,  3.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.921      0.843      0.911      0.767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/40      5.24G     0.7777     0.5891      1.004        201        640: 100%|██████████| 8/8 [00:02<00:00,  3.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.926      0.841      0.913       0.77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      31/40      5.24G      0.864      0.814      1.007        101        640: 100%|██████████| 8/8 [00:03<00:00,  2.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.869      0.871       0.91      0.764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      32/40      5.24G      0.897     0.8188      1.038        104        640: 100%|██████████| 8/8 [00:02<00:00,  3.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.924      0.831      0.909      0.759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      33/40      5.24G     0.8035      0.639      1.001        128        640: 100%|██████████| 8/8 [00:02<00:00,  2.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.922      0.829       0.91      0.756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      34/40      5.24G     0.8378     0.6799     0.9901        100        640: 100%|██████████| 8/8 [00:02<00:00,  3.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.926      0.827      0.909      0.755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      35/40      5.24G     0.8128     0.6742     0.9845         97        640: 100%|██████████| 8/8 [00:02<00:00,  3.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.924      0.824      0.909      0.753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      36/40      5.24G     0.7969     0.6108     0.9923        111        640: 100%|██████████| 8/8 [00:02<00:00,  3.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.929       0.82      0.911      0.757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      37/40      5.24G     0.7746     0.5731     0.9795        142        640: 100%|██████████| 8/8 [00:02<00:00,  3.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.918      0.826       0.91      0.757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      38/40      5.24G      0.815     0.6178     0.9839        131        640: 100%|██████████| 8/8 [00:02<00:00,  3.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.923      0.824       0.91      0.754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      39/40      5.24G     0.8126     0.5824     0.9827        115        640: 100%|██████████| 8/8 [00:02<00:00,  3.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.924      0.818      0.906      0.752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      40/40      5.24G      0.762     0.5949     0.9723        161        640: 100%|██████████| 8/8 [00:02<00:00,  3.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929       0.92       0.82      0.905      0.753\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 10 epochs. Best results observed at epoch 30, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "40 epochs completed in 0.047 hours.\n",
            "Optimizer stripped from coco128_improved/yolov8s_improved_run/weights/last.pt, 22.6MB\n",
            "Optimizer stripped from coco128_improved/yolov8s_improved_run/weights/best.pt, 22.6MB\n",
            "\n",
            "Validating coco128_improved/yolov8s_improved_run/weights/best.pt...\n",
            "Ultralytics 8.3.139 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,156,544 parameters, 0 gradients, 28.6 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.926      0.841      0.913       0.77\n",
            "                person         61        254       0.97      0.765      0.914      0.735\n",
            "               bicycle          3          6      0.942      0.833      0.842       0.53\n",
            "                   car         12         46      0.955      0.463      0.688      0.364\n",
            "            motorcycle          4          5      0.916          1      0.995      0.904\n",
            "              airplane          5          6      0.967          1      0.995      0.974\n",
            "                   bus          5          7      0.939          1      0.995       0.91\n",
            "                 train          3          3      0.913          1      0.995      0.995\n",
            "                 truck          5         12      0.901        0.5      0.673      0.484\n",
            "                  boat          2          6          1      0.713      0.873      0.709\n",
            "         traffic light          4         14      0.965      0.429      0.465      0.286\n",
            "             stop sign          2          2      0.864          1      0.995      0.995\n",
            "                 bench          5          9      0.987      0.778      0.939      0.822\n",
            "                  bird          2         16      0.979          1      0.995      0.798\n",
            "                   cat          4          4      0.931          1      0.995      0.932\n",
            "                   dog          9          9      0.973          1      0.995      0.863\n",
            "                 horse          1          2      0.882          1      0.995      0.803\n",
            "              elephant          4         17      0.978      0.941       0.99      0.913\n",
            "                  bear          1          1      0.788          1      0.995      0.995\n",
            "                 zebra          2          4      0.914          1      0.995      0.995\n",
            "               giraffe          4          9      0.964          1      0.995      0.901\n",
            "              backpack          4          6      0.962      0.833      0.838      0.621\n",
            "              umbrella          4         18       0.95      0.889      0.973      0.813\n",
            "               handbag          9         19      0.976      0.684      0.717      0.581\n",
            "                   tie          6          7      0.924      0.857       0.86      0.706\n",
            "              suitcase          2          4      0.952          1      0.995      0.881\n",
            "               frisbee          5          5       0.92        0.8      0.811      0.721\n",
            "                  skis          1          1      0.797          1      0.995      0.895\n",
            "             snowboard          2          7      0.869          1      0.995      0.827\n",
            "           sports ball          6          6      0.922      0.667      0.676      0.447\n",
            "                  kite          2         10       0.82        0.4      0.719      0.359\n",
            "          baseball bat          4          4          1      0.677      0.945      0.659\n",
            "        baseball glove          4          7      0.954      0.429      0.442      0.312\n",
            "            skateboard          3          5      0.925        0.8      0.938      0.699\n",
            "         tennis racket          5          7      0.919      0.714      0.718      0.551\n",
            "                bottle          6         18      0.972      0.667      0.921      0.688\n",
            "            wine glass          5         16          1      0.495      0.898      0.654\n",
            "                   cup         10         36       0.97      0.888      0.954      0.717\n",
            "                  fork          6          6          1      0.387      0.972      0.703\n",
            "                 knife          7         16       0.86      0.771      0.929      0.688\n",
            "                 spoon          5         22       0.78      0.591      0.701      0.569\n",
            "                  bowl          9         28      0.916      0.857      0.897      0.777\n",
            "                banana          1          1      0.794          1      0.995      0.995\n",
            "              sandwich          2          2      0.837          1      0.995      0.995\n",
            "                orange          1          4      0.883          1      0.995      0.823\n",
            "              broccoli          4         11          1      0.599      0.782      0.578\n",
            "                carrot          3         24      0.956      0.901      0.941      0.739\n",
            "               hot dog          1          2      0.854          1      0.995      0.995\n",
            "                 pizza          5          5      0.931          1      0.995      0.976\n",
            "                 donut          2         14      0.916          1      0.995      0.942\n",
            "                  cake          4          4      0.923          1      0.995      0.967\n",
            "                 chair          9         35      0.995        0.8      0.955      0.701\n",
            "                 couch          5          6      0.968          1      0.995      0.853\n",
            "          potted plant          9         14          1      0.963      0.995      0.881\n",
            "                   bed          3          3      0.893          1      0.995      0.941\n",
            "          dining table         10         13      0.945      0.923       0.99       0.87\n",
            "                toilet          2          2      0.861          1      0.995      0.995\n",
            "                    tv          2          2      0.861          1      0.995      0.995\n",
            "                laptop          2          3      0.863          1      0.995      0.995\n",
            "                 mouse          2          2      0.791        0.5      0.828      0.532\n",
            "                remote          5          8          1      0.723      0.879      0.673\n",
            "            cell phone          5          8      0.905      0.625      0.678      0.502\n",
            "             microwave          3          3      0.893          1      0.995      0.931\n",
            "                  oven          5          5          1      0.776      0.938       0.61\n",
            "                  sink          4          6      0.951      0.667      0.948      0.752\n",
            "          refrigerator          5          5      0.954          1      0.995      0.854\n",
            "                  book          6         29          1      0.524      0.841      0.572\n",
            "                 clock          8          9          1      0.978      0.995      0.888\n",
            "                  vase          2          2      0.854          1      0.995      0.995\n",
            "              scissors          1          1      0.935          1      0.995      0.697\n",
            "            teddy bear          6         21          1      0.882      0.954      0.795\n",
            "            toothbrush          2          5      0.899          1      0.995      0.885\n",
            "Speed: 0.2ms preprocess, 4.6ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
            "Results saved to \u001b[1mcoco128_improved/yolov8s_improved_run\u001b[0m\n",
            "Обучение улучшенной модели завершено.\n",
            "Лучшие веса сохранены в: coco128_improved/yolov8s_improved_run/weights/best.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.e. Оценка качества модели с улучшенным бейзлайном\n"
      ],
      "metadata": {
        "id": "mkbsFzNa_92a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if improved_weights_path and os.path.exists(improved_weights_path):\n",
        "    print(f\"Оценка улучшенной модели с весами: {improved_weights_path}\")\n",
        "    model_eval_improved = YOLO(improved_weights_path)\n",
        "\n",
        "    metrics_improved = model_eval_improved.val(\n",
        "        data=dataset_yaml,\n",
        "        imgsz=improved_imgsz,\n",
        "        split='val',\n",
        "        project=improved_project_name,\n",
        "        name=improved_experiment_name + \"_eval\",\n",
        "        exist_ok=True\n",
        "    )\n",
        "\n",
        "    print(\"\\nРезультаты оценки улучшенной модели:\")\n",
        "    if metrics_improved:\n",
        "        print(f\"  Precision(B): {metrics_improved.box.mp:.4f}\")\n",
        "        print(f\"  Recall(B): {metrics_improved.box.mr:.4f}\")\n",
        "        print(f\"  mAP50(B): {metrics_improved.box.map50:.4f}\")\n",
        "        print(f\"  mAP50-95(B): {metrics_improved.box.map:.4f}\")\n",
        "\n",
        "        results_history['improved'] = {\n",
        "            'model': improved_model_name.split('.')[0],\n",
        "            'weights': improved_weights_path,\n",
        "            'precision': metrics_improved.box.mp,\n",
        "            'recall': metrics_improved.box.mr,\n",
        "            'mAP50': metrics_improved.box.map50,\n",
        "            'mAP50-95': metrics_improved.box.map\n",
        "        }\n",
        "    else:\n",
        "        print(\"Не удалось получить метрики для улучшенной модели.\")\n",
        "        results_history['improved'] = {\n",
        "          'model': improved_model_name.split('.')[0],\n",
        "          'weights': \"N/A\",\n",
        "          'precision': 0, 'recall': 0, 'mAP50': 0, 'mAP50-95': 0\n",
        "        }\n",
        "else:\n",
        "    print(\"Файл с весами улучшенной модели не найден. Оценка невозможна.\")\n",
        "    results_history['improved'] = {\n",
        "          'model': improved_model_name.split('.')[0],\n",
        "          'weights': \"N/A\",\n",
        "          'precision': 0, 'recall': 0, 'mAP50': 0, 'mAP50-95': 0\n",
        "    }\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMaLM6Ws_610",
        "outputId": "5399be54-3d2f-45cb-e9f2-d818e3fcf128"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Оценка улучшенной модели с весами: coco128_improved/yolov8s_improved_run/weights/best.pt\n",
            "Ultralytics 8.3.139 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,156,544 parameters, 0 gradients, 28.6 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1529.0±633.8 MB/s, size: 53.4 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|██████████| 128/128 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.923      0.842       0.91      0.767\n",
            "                person         61        254       0.97      0.768      0.918      0.733\n",
            "               bicycle          3          6      0.941      0.833      0.841      0.538\n",
            "                   car         12         46      0.955      0.463      0.678      0.356\n",
            "            motorcycle          4          5      0.916          1      0.995      0.904\n",
            "              airplane          5          6      0.967          1      0.995      0.974\n",
            "                   bus          5          7      0.939          1      0.995      0.898\n",
            "                 train          3          3      0.913          1      0.995      0.953\n",
            "                 truck          5         12      0.901        0.5      0.673      0.471\n",
            "                  boat          2          6      0.904      0.667      0.821      0.593\n",
            "         traffic light          4         14      0.965      0.429      0.464      0.292\n",
            "             stop sign          2          2      0.864          1      0.995      0.923\n",
            "                 bench          5          9      0.987      0.778      0.939      0.822\n",
            "                  bird          2         16      0.979          1      0.995      0.798\n",
            "                   cat          4          4      0.929          1      0.995      0.932\n",
            "                   dog          9          9      0.972          1      0.995      0.876\n",
            "                 horse          1          2      0.882          1      0.995      0.803\n",
            "              elephant          4         17      0.978      0.941       0.99      0.906\n",
            "                  bear          1          1      0.789          1      0.995      0.995\n",
            "                 zebra          2          4      0.914          1      0.995      0.995\n",
            "               giraffe          4          9      0.964          1      0.995      0.901\n",
            "              backpack          4          6      0.969      0.833      0.838      0.604\n",
            "              umbrella          4         18      0.949      0.889      0.973      0.813\n",
            "               handbag          9         19      0.974      0.684      0.717      0.589\n",
            "                   tie          6          7      0.924      0.857       0.86      0.706\n",
            "              suitcase          2          4      0.953          1      0.995      0.882\n",
            "               frisbee          5          5       0.92        0.8      0.811      0.722\n",
            "                  skis          1          1      0.798          1      0.995      0.995\n",
            "             snowboard          2          7      0.869          1      0.995      0.827\n",
            "           sports ball          6          6      0.922      0.667      0.676      0.432\n",
            "                  kite          2         10      0.886        0.4      0.699       0.35\n",
            "          baseball bat          4          4          1      0.677      0.945      0.645\n",
            "        baseball glove          4          7      0.955      0.429      0.442      0.312\n",
            "            skateboard          3          5      0.925        0.8      0.938        0.7\n",
            "         tennis racket          5          7      0.753      0.714      0.738        0.6\n",
            "                bottle          6         18      0.972      0.667      0.923      0.687\n",
            "            wine glass          5         16          1      0.495      0.894      0.655\n",
            "                   cup         10         36       0.97      0.898      0.958      0.713\n",
            "                  fork          6          6          1      0.385      0.995      0.699\n",
            "                 knife          7         16       0.86      0.771      0.929      0.691\n",
            "                 spoon          5         22      0.781      0.591      0.701      0.562\n",
            "                  bowl          9         28      0.941      0.857      0.897      0.784\n",
            "                banana          1          1      0.794          1      0.995      0.995\n",
            "              sandwich          2          2      0.837          1      0.995      0.995\n",
            "                orange          1          4      0.883          1      0.995      0.823\n",
            "              broccoli          4         11          1      0.599       0.78      0.577\n",
            "                carrot          3         24      0.956      0.901      0.941      0.748\n",
            "               hot dog          1          2      0.854          1      0.995      0.995\n",
            "                 pizza          5          5      0.931          1      0.995      0.976\n",
            "                 donut          2         14      0.904          1       0.99      0.945\n",
            "                  cake          4          4      0.923          1      0.995      0.966\n",
            "                 chair          9         35      0.994        0.8      0.953      0.706\n",
            "                 couch          5          6      0.968          1      0.995      0.836\n",
            "          potted plant          9         14          1      0.963      0.995      0.875\n",
            "                   bed          3          3      0.892          1      0.995      0.941\n",
            "          dining table         10         13          1      0.957      0.995      0.855\n",
            "                toilet          2          2      0.861          1      0.995      0.995\n",
            "                    tv          2          2      0.859          1      0.995      0.995\n",
            "                laptop          2          3       0.73          1      0.995      0.995\n",
            "                 mouse          2          2      0.805        0.5      0.662       0.45\n",
            "                remote          5          8          1      0.777      0.879      0.673\n",
            "            cell phone          5          8      0.915      0.625      0.678      0.509\n",
            "             microwave          3          3      0.893          1      0.995      0.931\n",
            "                  oven          5          5          1      0.775      0.938       0.61\n",
            "                  sink          4          6      0.952      0.667      0.948      0.752\n",
            "          refrigerator          5          5      0.954          1      0.995      0.854\n",
            "                  book          6         29          1      0.511      0.839      0.581\n",
            "                 clock          8          9          1      0.978      0.995      0.887\n",
            "                  vase          2          2      0.854          1      0.995      0.995\n",
            "              scissors          1          1      0.935          1      0.995      0.697\n",
            "            teddy bear          6         21      0.991      0.905      0.943      0.792\n",
            "            toothbrush          2          5      0.904          1      0.995      0.885\n",
            "Speed: 2.6ms preprocess, 8.3ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
            "Results saved to \u001b[1mcoco128_improved/yolov8s_improved_run_eval\u001b[0m\n",
            "\n",
            "Результаты оценки улучшенной модели:\n",
            "  Precision(B): 0.9231\n",
            "  Recall(B): 0.8415\n",
            "  mAP50(B): 0.9104\n",
            "  mAP50-95(B): 0.7671\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.f. Сравнение результатов моделей с улучшенным бейзлайном в сравнении с результатами из пункта 2\n"
      ],
      "metadata": {
        "id": "uXuwMkG_ABHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Вывод таблицы сравнения результатов\n",
        "print(\"Сравнение результатов:\")\n",
        "print(\"--------------------------------------------------------------------------------------------\")\n",
        "print(f\"{'Модель':<25} | {'Precision':<10} | {'Recall':<10} | {'mAP@.50':<10} | {'mAP@.50-.95':<12}\")\n",
        "print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "if 'baseline' in results_history:\n",
        "    b = results_history['baseline']\n",
        "    print(f\"{'YOLOv8n (Бейзлайн)':<25} | {b['precision']:.4f}   | {b['recall']:.4f}   | {b['mAP50']:.4f}   | {b['mAP50-95']:.4f}\")\n",
        "else:\n",
        "    print(f\"{'YOLOv8n (Бейзлайн)':<25} | N/A        | N/A        | N/A        | N/A\")\n",
        "\n",
        "\n",
        "if 'improved' in results_history:\n",
        "    i = results_history['improved']\n",
        "    print(f\"{'YOLOv8s (Улучшенный)':<25} | {i['precision']:.4f}   | {i['recall']:.4f}   | {i['mAP50']:.4f}   | {i['mAP50-95']:.4f}\")\n",
        "\n",
        "    if 'baseline' in results_history and b['mAP50-95'] > 0 : # Проверка, что есть с чем сравнивать\n",
        "        print(\"--------------------------------------------------------------------------------------------\")\n",
        "        print(\"Изменения относительно бейзлайна:\")\n",
        "        precision_diff = (i['precision'] - b['precision']) / b['precision'] * 100 if b['precision'] != 0 else float('inf')\n",
        "        recall_diff = (i['recall'] - b['recall']) / b['recall'] * 100 if b['recall'] != 0 else float('inf')\n",
        "        map50_diff = (i['mAP50'] - b['mAP50']) / b['mAP50'] * 100 if b['mAP50'] != 0 else float('inf')\n",
        "        map_total_diff = (i['mAP50-95'] - b['mAP50-95']) / b['mAP50-95'] * 100 if b['mAP50-95'] != 0 else float('inf')\n",
        "\n",
        "        print(f\"  Δ Precision: {precision_diff:+.2f}%\")\n",
        "        print(f\"  Δ Recall: {recall_diff:+.2f}%\")\n",
        "        print(f\"  Δ mAP@.50: {map50_diff:+.2f}%\")\n",
        "        print(f\"  Δ mAP@.50-.95: {map_total_diff:+.2f}%\")\n",
        "\n",
        "else:\n",
        "    print(f\"{'YOLOv8s (Улучшенный)':<25} | N/A        | N/A        | N/A        | N/A\")\n",
        "\n",
        "print(\"--------------------------------------------------------------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Eg4uoZnAFWF",
        "outputId": "04f94395-498a-4964-a074-3832480ad046"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Сравнение результатов:\n",
            "--------------------------------------------------------------------------------------------\n",
            "Модель                    | Precision  | Recall     | mAP@.50    | mAP@.50-.95 \n",
            "--------------------------------------------------------------------------------------------\n",
            "YOLOv8n (Бейзлайн)        | 0.7630   | 0.7279   | 0.7858   | 0.6047\n",
            "YOLOv8s (Улучшенный)      | 0.9231   | 0.8415   | 0.9104   | 0.7671\n",
            "--------------------------------------------------------------------------------------------\n",
            "Изменения относительно бейзлайна:\n",
            "  Δ Precision: +20.99%\n",
            "  Δ Recall: +15.61%\n",
            "  Δ mAP@.50: +15.86%\n",
            "  Δ mAP@.50-.95: +26.86%\n",
            "--------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.g. Выводы по улучшению бейзлайна\n",
        "\n",
        "По результатам проведенных экспериментов можно сделать следующие выводы:\n",
        "\n",
        "*   **Исходный бейзлайн (YOLOv8n):** Модель `YOLOv8n` с параметрами обучения (`25` эпох, размер изображения `640x640` – *предполагается на основе типичных настроек из предоставленного ранее ноутбука, уточните если ваши параметры отличались*) показала следующие результаты:\n",
        "    *   Precision: `0.7630`\n",
        "    *   Recall: `0.7279`\n",
        "    *   mAP@0.5: `0.7858`\n",
        "    *   mAP@0.5:0.95: `0.6047`\n",
        "    Эти результаты служат отправной точкой для сравнения.\n",
        "\n",
        "*   **Улучшенный бейзлайн (YOLOv8s):** После применения гипотез по улучшению (использование модели `YOLOv8s`, увеличение количества эпох до `40` – *предполагается на основе типичных настроек `baseline_epochs + 15` из предоставленного ранее ноутбука, уточните если ваши параметры отличались*, при сохранении размера изображения `640x640`), были получены следующие метрики:\n",
        "    *   Precision: `0.9231`\n",
        "    *   Recall: `0.8415`\n",
        "    *   mAP@0.5: `0.9104`\n",
        "    *   mAP@0.5:0.95: `0.7671`\n",
        "\n",
        "*   **Сравнение:**\n",
        "    *   Улучшенная модель показала **значительное улучшение** метрики mAP@0.5:0.95 на `26.86%` по сравнению с бейзлайном.\n",
        "    *   Метрика mAP@0.5 **улучшилась** на `15.86%`.\n",
        "    *   Precision **существенно изменилось** c `0.7630` до `0.9231` (рост на `20.99%`), а Recall также **значительно изменилось** c `0.7279` до `0.8415` (рост на `15.61%`).\n",
        "    *   Гипотеза об использовании более крупной модели (`YOLOv8s` вместо `YOLOv8n`) в сочетании с увеличением числа эпох обучения полностью подтвердилась, что привело к существенному росту всех ключевых метрик качества обнаружения.\n",
        "\n",
        "*   **Общий вывод:** Предпринятые шаги по улучшению (переход на более крупную архитектуру `YOLOv8s` и увеличение количества эпох обучения) привели к **однозначно положительному** результату, выразившемуся в заметном повышении всех оцениваемых метрик. Это демонстрирует эффективность выбора более мощной модели и достаточного времени для ее обучения на заданном датасете. Для дальнейшего улучшения можно рассмотреть более тонкую настройку гиперпараметров (например, скорости обучения, параметров аугментации), использование еще большего количества эпох или применение более сложных техник аугментации данных.\n",
        "\n",
        "## 4. Имплементация алгоритма машинного обучения\n",
        "\n",
        "В контексте Ultralytics YOLO, \"самостоятельная имплементация\" может означать не создание всей архитектуры с нуля (что является очень объемной задачей), а, например:\n",
        "1.  Обучение модели YOLO **\"с нуля\"** (from scratch), используя только YAML-файл конфигурации архитектуры, а не предварительно обученные веса (`.pt` файл). Это позволяет понять процесс обучения без влияния предварительной подготовки на больших датасетах типа COCO.\n",
        "2.  Создание собственной конфигурации модели (кастомный YAML), изменяя слои, анкеры и т.д. (более сложный вариант).\n",
        "3.  Реализация кастомного цикла обучения или функции потерь (также продвинутый вариант).\n",
        "\n",
        "Для данной лабораторной работы мы выберем **первый вариант**: обучим стандартную архитектуру YOLOv8 (например, YOLOv8n) \"с нуля\", используя ее `.yaml` файл. Это позволит нам сравнить результаты обучения с использованием предобученных весов (fine-tuning) и обучения с случайно инициализированными весами.\n",
        "\n",
        "### 4.a. \"Самостоятельная имплементация\" - обучение модели YOLO с нуля (from scratch)\n",
        "\n",
        "Вместо `yolov8n.pt` (предобученные веса), мы используем `yolov8n.yaml` (определение архитектуры)\n",
        "Это означает, что модель будет инициализирована случайными весами и обучена только на нашем датасете coco128\n"
      ],
      "metadata": {
        "id": "hh6ZuxwGAIkE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Задаем параметры для обучения \"с нуля\"\n",
        "custom_model_yaml = 'yolov8n.yaml' # Определяет архитектуру, но не веса\n",
        "# Для обучения с нуля обычно требуется больше эпох, чем для fine-tuning\n",
        "# Но для демонстрации оставим сопоставимое количество, как у улучшенного бейзлайна\n",
        "custom_epochs = improved_epochs # Используем то же количество эпох, что и для лучшей модели выше\n",
        "custom_imgsz = baseline_imgsz # Тот же размер изображения\n",
        "custom_project_name = 'coco128_custom_scratch'\n",
        "custom_experiment_name = 'yolov8n_from_scratch_run'\n",
        "\n",
        "print(f\"Обучение 'кастомной' модели (с нуля): {custom_model_yaml}\")\n",
        "print(f\"Датасет: {dataset_yaml}\")\n",
        "print(f\"Количество эпох: {custom_epochs}\")\n",
        "print(f\"Размер изображения: {custom_imgsz}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbK-HeGtAT2s",
        "outputId": "d9864f59-90b1-4cff-e487-9af8d9104c1c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обучение 'кастомной' модели (с нуля): yolov8n.yaml\n",
            "Датасет: coco128.yaml\n",
            "Количество эпох: 40\n",
            "Размер изображения: 640\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.b. Обучение имплементированной модели\n",
        "\n",
        "Создаем модель на основе YAML конфигурации"
      ],
      "metadata": {
        "id": "kr6faKzyAc1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_custom_scratch = YOLO(custom_model_yaml) # Загрузка архитектуры\n",
        "\n",
        "try:\n",
        "    history_custom_scratch = model_custom_scratch.train(\n",
        "        data=dataset_yaml,\n",
        "        epochs=custom_epochs,\n",
        "        imgsz=custom_imgsz,\n",
        "        project=custom_project_name,\n",
        "        name=custom_experiment_name,\n",
        "        exist_ok=True,\n",
        "        patience=5 # Установим такое же patience, как в baseline\n",
        "    )\n",
        "    print(\"Обучение 'кастомной' модели (с нуля) завершено.\")\n",
        "    custom_scratch_weights_path = os.path.join(custom_project_name, custom_experiment_name, 'weights', 'best.pt')\n",
        "    print(f\"Лучшие веса сохранены в: {custom_scratch_weights_path}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка во время обучения 'кастомной' модели (с нуля): {e}\")\n",
        "    history_custom_scratch = None\n",
        "    custom_scratch_weights_path = None\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95fhi5pvAbg9",
        "outputId": "c3c02af9-9889-45bc-c378-c3d02b59b038"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.139 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=coco128.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=40, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.yaml, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8n_from_scratch_run, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=5, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=coco128_custom_scratch, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=coco128_custom_scratch/yolov8n_from_scratch_run, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "YOLOv8n summary: 129 layers, 3,157,200 parameters, 3,157,184 gradients, 8.9 GFLOPs\n",
            "\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1288.0±455.3 MB/s, size: 50.9 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|██████████| 128/128 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 385.2±87.7 MB/s, size: 52.5 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|██████████| 128/128 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to coco128_custom_scratch/yolov8n_from_scratch_run/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mcoco128_custom_scratch/yolov8n_from_scratch_run\u001b[0m\n",
            "Starting training for 40 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/40      2.66G      3.453      5.758       4.28        172        640: 100%|██████████| 8/8 [00:02<00:00,  2.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/40      2.66G      3.563      5.763      4.299        231        640: 100%|██████████| 8/8 [00:02<00:00,  3.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/40      2.66G      3.525      5.717      4.266        192        640: 100%|██████████| 8/8 [00:01<00:00,  4.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/40      2.67G      3.555      5.731      4.259        215        640: 100%|██████████| 8/8 [00:01<00:00,  4.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/40      2.68G       3.51      5.685      4.265        236        640: 100%|██████████| 8/8 [00:01<00:00,  4.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  4.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/40      2.69G      3.569      5.686      4.263        253        640: 100%|██████████| 8/8 [00:02<00:00,  3.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/40      2.69G      3.553      5.686      4.231        282        640: 100%|██████████| 8/8 [00:01<00:00,  4.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/40      2.71G      3.549      5.678      4.237        192        640: 100%|██████████| 8/8 [00:01<00:00,  4.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/40      2.71G       3.49      5.686      4.218        180        640: 100%|██████████| 8/8 [00:01<00:00,  4.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/40      2.73G      3.589      5.648      4.214        180        640: 100%|██████████| 8/8 [00:02<00:00,  3.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/40      2.73G      3.565      5.636      4.215        263        640: 100%|██████████| 8/8 [00:01<00:00,  4.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/40      2.73G       3.65      5.659      4.198        176        640: 100%|██████████| 8/8 [00:01<00:00,  4.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/40      2.73G      3.652      5.639      4.192        251        640: 100%|██████████| 8/8 [00:01<00:00,  4.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/40      2.73G      3.514      5.609      4.193        208        640: 100%|██████████| 8/8 [00:02<00:00,  3.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/40      2.73G      3.597      5.585      4.187        251        640: 100%|██████████| 8/8 [00:01<00:00,  4.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/40      2.73G      3.631      5.629      4.182        189        640: 100%|██████████| 8/8 [00:01<00:00,  4.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/40      2.73G      3.505      5.595      4.178        184        640: 100%|██████████| 8/8 [00:01<00:00,  4.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/40      2.73G      3.581      5.603      4.174        208        640: 100%|██████████| 8/8 [00:01<00:00,  4.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/40      2.73G      3.553      5.551      4.171        169        640: 100%|██████████| 8/8 [00:02<00:00,  3.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/40      2.73G      3.618      5.562      4.162        185        640: 100%|██████████| 8/8 [00:01<00:00,  4.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  5.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/40      2.75G      3.597       5.51      4.158        317        640: 100%|██████████| 8/8 [00:01<00:00,  4.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  4.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929   0.000124   5.55e-05   6.23e-05   6.23e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/40      2.75G      3.481      5.575      4.158        255        640: 100%|██████████| 8/8 [00:01<00:00,  4.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  4.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929   3.17e-05   5.55e-05   1.68e-05   1.68e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/40      2.75G       3.56      5.558      4.155        227        640: 100%|██████████| 8/8 [00:02<00:00,  3.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929     0.0141    0.00179    0.00786   0.000795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/40      2.75G      3.519      5.512      4.151        196        640: 100%|██████████| 8/8 [00:01<00:00,  4.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929    0.00123     0.0019    0.00217   0.000651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/40      2.75G      3.595      5.498      4.147        244        640: 100%|██████████| 8/8 [00:01<00:00,  4.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929    0.00394    0.00477    0.00461    0.00106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/40      2.76G      3.581      5.494      4.144        228        640: 100%|██████████| 8/8 [00:01<00:00,  4.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  4.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929    0.00117    0.00483    0.00221   0.000801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/40      2.76G      3.536      5.463      4.136        202        640: 100%|██████████| 8/8 [00:02<00:00,  3.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.269    0.00483    0.00595    0.00169\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/40      2.78G      3.448      5.485      4.147        229        640: 100%|██████████| 8/8 [00:01<00:00,  4.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.679    0.00156    0.00543     0.0014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/40      2.78G      3.535      5.476      4.139        169        640: 100%|██████████| 8/8 [00:01<00:00,  4.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.708    0.00156     0.0037   0.000995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/40      2.78G      3.457      5.463      4.137        201        640: 100%|██████████| 8/8 [00:01<00:00,  4.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  4.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.756    0.00156    0.00262   0.000725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      31/40      2.78G      3.472       5.61      4.136        101        640: 100%|██████████| 8/8 [00:03<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.725    0.00156    0.00313    0.00077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      32/40      2.78G      3.516      5.621      4.142        104        640: 100%|██████████| 8/8 [00:01<00:00,  4.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929       0.77    0.00156    0.00371   0.000838\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 5 epochs. Best results observed at epoch 27, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=5) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "32 epochs completed in 0.029 hours.\n",
            "Optimizer stripped from coco128_custom_scratch/yolov8n_from_scratch_run/weights/last.pt, 6.5MB\n",
            "Optimizer stripped from coco128_custom_scratch/yolov8n_from_scratch_run/weights/best.pt, 6.5MB\n",
            "\n",
            "Validating coco128_custom_scratch/yolov8n_from_scratch_run/weights/best.pt...\n",
            "Ultralytics 8.3.139 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLOv8n summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.564    0.00162    0.00593    0.00154\n",
            "                person         61        254    0.00178    0.00394     0.0034   0.000819\n",
            "               bicycle          3          6          0          0          0          0\n",
            "                   car         12         46          0          0          0          0\n",
            "            motorcycle          4          5          1          0          0          0\n",
            "              airplane          5          6          1          0          0          0\n",
            "                   bus          5          7          1          0          0          0\n",
            "                 train          3          3          1          0          0          0\n",
            "                 truck          5         12          1          0          0          0\n",
            "                  boat          2          6          0          0          0          0\n",
            "         traffic light          4         14          0          0          0          0\n",
            "             stop sign          2          2          1          0          0          0\n",
            "                 bench          5          9          1          0          0          0\n",
            "                  bird          2         16          0          0          0          0\n",
            "                   cat          4          4          1          0          0          0\n",
            "                   dog          9          9     0.0427      0.111      0.122     0.0301\n",
            "                 horse          1          2          0          0          0          0\n",
            "              elephant          4         17          1          0          0          0\n",
            "                  bear          1          1          0          0          0          0\n",
            "                 zebra          2          4          1          0          0          0\n",
            "               giraffe          4          9          1          0          0          0\n",
            "              backpack          4          6          0          0          0          0\n",
            "              umbrella          4         18          1          0          0          0\n",
            "               handbag          9         19          0          0          0          0\n",
            "                   tie          6          7          1          0          0          0\n",
            "              suitcase          2          4          0          0          0          0\n",
            "               frisbee          5          5          1          0      0.209     0.0431\n",
            "                  skis          1          1          1          0          0          0\n",
            "             snowboard          2          7          1          0          0          0\n",
            "           sports ball          6          6          0          0          0          0\n",
            "                  kite          2         10          1          0          0          0\n",
            "          baseball bat          4          4          1          0          0          0\n",
            "        baseball glove          4          7          0          0          0          0\n",
            "            skateboard          3          5          1          0          0          0\n",
            "         tennis racket          5          7          0          0          0          0\n",
            "                bottle          6         18          0          0          0          0\n",
            "            wine glass          5         16          0          0          0          0\n",
            "                   cup         10         36          0          0          0          0\n",
            "                  fork          6          6          0          0          0          0\n",
            "                 knife          7         16          1          0          0          0\n",
            "                 spoon          5         22          0          0          0          0\n",
            "                  bowl          9         28          1          0          0          0\n",
            "                banana          1          1          0          0          0          0\n",
            "              sandwich          2          2          1          0          0          0\n",
            "                orange          1          4          1          0          0          0\n",
            "              broccoli          4         11          1          0          0          0\n",
            "                carrot          3         24          1          0          0          0\n",
            "               hot dog          1          2          0          0          0          0\n",
            "                 pizza          5          5          1          0          0          0\n",
            "                 donut          2         14          0          0          0          0\n",
            "                  cake          4          4          1          0          0          0\n",
            "                 chair          9         35          1          0     0.0878     0.0351\n",
            "                 couch          5          6          1          0          0          0\n",
            "          potted plant          9         14          1          0          0          0\n",
            "                   bed          3          3          0          0          0          0\n",
            "          dining table         10         13          1          0          0          0\n",
            "                toilet          2          2          0          0          0          0\n",
            "                    tv          2          2          1          0          0          0\n",
            "                laptop          2          3          1          0          0          0\n",
            "                 mouse          2          2          1          0          0          0\n",
            "                remote          5          8          1          0          0          0\n",
            "            cell phone          5          8          0          0          0          0\n",
            "             microwave          3          3          0          0          0          0\n",
            "                  oven          5          5          1          0          0          0\n",
            "                  sink          4          6          0          0          0          0\n",
            "          refrigerator          5          5          0          0          0          0\n",
            "                  book          6         29          1          0          0          0\n",
            "                 clock          8          9          0          0          0          0\n",
            "                  vase          2          2          1          0          0          0\n",
            "              scissors          1          1          0          0          0          0\n",
            "            teddy bear          6         21          1          0          0          0\n",
            "            toothbrush          2          5          1          0          0          0\n",
            "Speed: 0.4ms preprocess, 2.5ms inference, 0.0ms loss, 4.5ms postprocess per image\n",
            "Results saved to \u001b[1mcoco128_custom_scratch/yolov8n_from_scratch_run\u001b[0m\n",
            "Обучение 'кастомной' модели (с нуля) завершено.\n",
            "Лучшие веса сохранены в: coco128_custom_scratch/yolov8n_from_scratch_run/weights/best.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.c. Оценка качества имплементированной модели (обученной с нуля)\n"
      ],
      "metadata": {
        "id": "oSnSsRgSCi2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if custom_scratch_weights_path and os.path.exists(custom_scratch_weights_path):\n",
        "    print(f\"Оценка 'кастомной' модели (с нуля) с весами: {custom_scratch_weights_path}\")\n",
        "    model_eval_custom_scratch = YOLO(custom_scratch_weights_path)\n",
        "\n",
        "    metrics_custom_scratch = model_eval_custom_scratch.val(\n",
        "        data=dataset_yaml,\n",
        "        imgsz=custom_imgsz,\n",
        "        split='val',\n",
        "        project=custom_project_name,\n",
        "        name=custom_experiment_name + \"_eval\",\n",
        "        exist_ok=True\n",
        "    )\n",
        "\n",
        "    print(\"\\nРезультаты оценки 'кастомной' модели (обученной с нуля):\")\n",
        "    if metrics_custom_scratch:\n",
        "        print(f\"  Precision(B): {metrics_custom_scratch.box.mp:.4f}\")\n",
        "        print(f\"  Recall(B): {metrics_custom_scratch.box.mr:.4f}\")\n",
        "        print(f\"  mAP50(B): {metrics_custom_scratch.box.map50:.4f}\")\n",
        "        print(f\"  mAP50-95(B): {metrics_custom_scratch.box.map:.4f}\")\n",
        "\n",
        "        results_history['custom_scratch'] = {\n",
        "            'model': custom_model_yaml.split('.')[0] + \" (scratch)\",\n",
        "            'weights': custom_scratch_weights_path,\n",
        "            'precision': metrics_custom_scratch.box.mp,\n",
        "            'recall': metrics_custom_scratch.box.mr,\n",
        "            'mAP50': metrics_custom_scratch.box.map50,\n",
        "            'mAP50-95': metrics_custom_scratch.box.map\n",
        "        }\n",
        "    else:\n",
        "        print(\"Не удалось получить метрики для 'кастомной' модели (с нуля).\")\n",
        "        results_history['custom_scratch'] = {\n",
        "          'model': custom_model_yaml.split('.')[0] + \" (scratch)\",\n",
        "          'weights': \"N/A\",\n",
        "          'precision': 0, 'recall': 0, 'mAP50': 0, 'mAP50-95': 0\n",
        "        }\n",
        "else:\n",
        "    print(\"Файл с весами 'кастомной' модели (с нуля) не найден. Оценка невозможна.\")\n",
        "    results_history['custom_scratch'] = {\n",
        "          'model': custom_model_yaml.split('.')[0] + \" (scratch)\",\n",
        "          'weights': \"N/A\",\n",
        "          'precision': 0, 'recall': 0, 'mAP50': 0, 'mAP50-95': 0\n",
        "        }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nexh6B87ChLM",
        "outputId": "5d7ebff2-96f4-4bcb-ad5e-b8a287fb07fe"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Оценка 'кастомной' модели (с нуля) с весами: coco128_custom_scratch/yolov8n_from_scratch_run/weights/best.pt\n",
            "Ultralytics 8.3.139 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLOv8n summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1618.9±846.2 MB/s, size: 53.4 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|██████████| 128/128 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.482    0.00471    0.00468    0.00102\n",
            "                person         61        254    0.00629     0.0236    0.00272   0.000669\n",
            "               bicycle          3          6          0          0          0          0\n",
            "                   car         12         46          0          0          0          0\n",
            "            motorcycle          4          5          0          0          0          0\n",
            "              airplane          5          6          1          0          0          0\n",
            "                   bus          5          7          1          0          0          0\n",
            "                 train          3          3          0          0          0          0\n",
            "                 truck          5         12          1          0          0          0\n",
            "                  boat          2          6          0          0          0          0\n",
            "         traffic light          4         14          0          0          0          0\n",
            "             stop sign          2          2          1          0          0          0\n",
            "                 bench          5          9          1          0          0          0\n",
            "                  bird          2         16          0          0          0          0\n",
            "                   cat          4          4          1          0          0          0\n",
            "                   dog          9          9     0.0292      0.111      0.121     0.0288\n",
            "                 horse          1          2          0          0          0          0\n",
            "              elephant          4         17          1          0          0          0\n",
            "                  bear          1          1          0          0          0          0\n",
            "                 zebra          2          4          1          0          0          0\n",
            "               giraffe          4          9          1          0          0          0\n",
            "              backpack          4          6          0          0          0          0\n",
            "              umbrella          4         18          1          0          0          0\n",
            "               handbag          9         19          0          0          0          0\n",
            "                   tie          6          7          1          0          0          0\n",
            "              suitcase          2          4          0          0          0          0\n",
            "               frisbee          5          5      0.195        0.2      0.208     0.0429\n",
            "                  skis          1          1          1          0          0          0\n",
            "             snowboard          2          7          1          0          0          0\n",
            "           sports ball          6          6          0          0          0          0\n",
            "                  kite          2         10          1          0          0          0\n",
            "          baseball bat          4          4          0          0          0          0\n",
            "        baseball glove          4          7          1          0          0          0\n",
            "            skateboard          3          5          1          0          0          0\n",
            "         tennis racket          5          7          0          0          0          0\n",
            "                bottle          6         18          0          0          0          0\n",
            "            wine glass          5         16          0          0          0          0\n",
            "                   cup         10         36          1          0          0          0\n",
            "                  fork          6          6          0          0          0          0\n",
            "                 knife          7         16          1          0          0          0\n",
            "                 spoon          5         22          0          0          0          0\n",
            "                  bowl          9         28          0          0          0          0\n",
            "                banana          1          1          0          0          0          0\n",
            "              sandwich          2          2          1          0          0          0\n",
            "                orange          1          4          1          0          0          0\n",
            "              broccoli          4         11          1          0          0          0\n",
            "                carrot          3         24          0          0          0          0\n",
            "               hot dog          1          2          0          0          0          0\n",
            "                 pizza          5          5          1          0          0          0\n",
            "                 donut          2         14          0          0          0          0\n",
            "                  cake          4          4          0          0          0          0\n",
            "                 chair          9         35          0          0          0          0\n",
            "                 couch          5          6          1          0          0          0\n",
            "          potted plant          9         14          1          0          0          0\n",
            "                   bed          3          3          0          0          0          0\n",
            "          dining table         10         13          0          0          0          0\n",
            "                toilet          2          2          0          0          0          0\n",
            "                    tv          2          2          1          0          0          0\n",
            "                laptop          2          3          1          0          0          0\n",
            "                 mouse          2          2          1          0          0          0\n",
            "                remote          5          8          1          0          0          0\n",
            "            cell phone          5          8          0          0          0          0\n",
            "             microwave          3          3          0          0          0          0\n",
            "                  oven          5          5          1          0          0          0\n",
            "                  sink          4          6          0          0          0          0\n",
            "          refrigerator          5          5          1          0          0          0\n",
            "                  book          6         29          1          0          0          0\n",
            "                 clock          8          9          1          0          0          0\n",
            "                  vase          2          2          0          0          0          0\n",
            "              scissors          1          1          0          0          0          0\n",
            "            teddy bear          6         21          1          0          0          0\n",
            "            toothbrush          2          5          1          0          0          0\n",
            "Speed: 3.4ms preprocess, 4.8ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
            "Results saved to \u001b[1mcoco128_custom_scratch/yolov8n_from_scratch_run_eval\u001b[0m\n",
            "\n",
            "Результаты оценки 'кастомной' модели (обученной с нуля):\n",
            "  Precision(B): 0.4821\n",
            "  Recall(B): 0.0047\n",
            "  mAP50(B): 0.0047\n",
            "  mAP50-95(B): 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.d. Сравнение результатов имплементированных моделей (обученных с нуля) в сравнении с результатами из пункта 2 (бейзлайн)\n"
      ],
      "metadata": {
        "id": "yLaKUfFCCpiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Сравнение результатов: Бейзлайн vs. Обучение с нуля\")\n",
        "print(\"--------------------------------------------------------------------------------------------\")\n",
        "print(f\"{'Модель':<30} | {'Precision':<10} | {'Recall':<10} | {'mAP@.50':<10} | {'mAP@.50-.95':<12}\")\n",
        "print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "if 'baseline' in results_history:\n",
        "    b = results_history['baseline']\n",
        "    print(f\"{'YOLOv8n (Бейзлайн, fine-tune)':<30} | {b['precision']:.4f}   | {b['recall']:.4f}   | {b['mAP50']:.4f}   | {b['mAP50-95']:.4f}\")\n",
        "else:\n",
        "    print(f\"{'YOLOv8n (Бейзлайн, fine-tune)':<30} | N/A        | N/A        | N/A        | N/A\")\n",
        "\n",
        "if 'custom_scratch' in results_history:\n",
        "    cs = results_history['custom_scratch']\n",
        "    print(f\"{'YOLOv8n (Кастом, с нуля)':<30} | {cs['precision']:.4f}   | {cs['recall']:.4f}   | {cs['mAP50']:.4f}   | {cs['mAP50-95']:.4f}\")\n",
        "\n",
        "    if 'baseline' in results_history and b['mAP50-95'] > 0 :\n",
        "        print(\"--------------------------------------------------------------------------------------------\")\n",
        "        print(\"Изменения 'с нуля' относительно бейзлайна (fine-tune):\")\n",
        "        precision_diff_cs = (cs['precision'] - b['precision']) / b['precision'] * 100 if b['precision'] != 0 else float('inf')\n",
        "        recall_diff_cs = (cs['recall'] - b['recall']) / b['recall'] * 100 if b['recall'] != 0 else float('inf')\n",
        "        map50_diff_cs = (cs['mAP50'] - b['mAP50']) / b['mAP50'] * 100 if b['mAP50'] != 0 else float('inf')\n",
        "        map_total_diff_cs = (cs['mAP50-95'] - b['mAP50-95']) / b['mAP50-95'] * 100 if b['mAP50-95'] != 0 else float('inf')\n",
        "\n",
        "        print(f\"  Δ Precision: {precision_diff_cs:+.2f}%\")\n",
        "        print(f\"  Δ Recall: {recall_diff_cs:+.2f}%\")\n",
        "        print(f\"  Δ mAP@.50: {map50_diff_cs:+.2f}%\")\n",
        "        print(f\"  Δ mAP@.50-.95: {map_total_diff_cs:+.2f}%\")\n",
        "else:\n",
        "    print(f\"{'YOLOv8n (Кастом, с нуля)':<30} | N/A        | N/A        | N/A        | N/A\")\n",
        "\n",
        "print(\"--------------------------------------------------------------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZ51CyIACp3I",
        "outputId": "784b8d6e-a59a-49b8-fadb-7b98b1316917"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Сравнение результатов: Бейзлайн vs. Обучение с нуля\n",
            "--------------------------------------------------------------------------------------------\n",
            "Модель                         | Precision  | Recall     | mAP@.50    | mAP@.50-.95 \n",
            "--------------------------------------------------------------------------------------------\n",
            "YOLOv8n (Бейзлайн, fine-tune)  | 0.7630   | 0.7279   | 0.7858   | 0.6047\n",
            "YOLOv8n (Кастом, с нуля)       | 0.4821   | 0.0047   | 0.0047   | 0.0010\n",
            "--------------------------------------------------------------------------------------------\n",
            "Изменения 'с нуля' относительно бейзлайна (fine-tune):\n",
            "  Δ Precision: -36.81%\n",
            "  Δ Recall: -99.35%\n",
            "  Δ mAP@.50: -99.40%\n",
            "  Δ mAP@.50-.95: -99.83%\n",
            "--------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.e. Выводы по сравнению \"имплементированной\" модели (с нуля) с бейзлайном (fine-tune)\n",
        "\n",
        "*   **Бейзлайн (fine-tune `yolov8n.pt`):** Модель, дообученная на основе предварительно обученных на COCO весов, показала mAP@0.5:0.95 = `0.6047`.\n",
        "*   **\"Кастомная\" модель (train from scratch `yolov8n.yaml`):** Модель той же архитектуры (`YOLOv8n`), но обученная с нуля только на датасете COCO128 (предположительно, с тем же количеством эпох, что и улучшенный бейзлайн, например, `40` эпох – *уточните, если число эпох отличалось*), показала mAP@0.5:0.95 = `0.0010`.\n",
        "\n",
        "*   **Сравнение:**\n",
        "    *   Обучение с нуля привело к **катастрофическому ухудшению** качества по сравнению с дообучением (fine-tuning) предварительно обученной модели. Разница в mAP@0.5:0.95 составила `-99.83%` (падение с 0.6047 до 0.0010).\n",
        "    *   Особенно показательно падение метрики Recall (`-99.35%` с `0.7279` до `0.0047`), что свидетельствует о почти полной неспособности модели, обученной с нуля на таком малом датасете, обнаруживать объекты. Метрика mAP@0.5 также упала на `99.40%`.\n",
        "    *   Это **ожидаемый результат**, поскольку COCO128 является очень маленьким датасетом. Предварительное обучение на большом и разнообразном наборе данных (полный COCO) дает модели хорошее начальное представление о признаках объектов, что позволяет ей быстрее и качественнее адаптироваться к целевому датасету при дообучении. Обучение с нуля на COCO128, даже с достаточным количеством эпох для fine-tuning более крупной модели, не позволяет модели выучить сколь-нибудь значимые представления объектов.\n",
        "    *   Результаты не являются неожиданными и полностью соответствуют теории transfer learning.\n",
        "\n",
        "*   **Общий вывод:** Дообучение (fine-tuning) предобученных моделей является **однозначно предпочтительной** стратегией при работе с небольшими целевыми наборами данных, так как позволяет достичь несравненно лучших результатов по сравнению с обучением \"с нуля\". Для обучения \"с нуля\" на малых датасетах, таких как COCO128, даже при сопоставимом или увеличенном количестве эпох, модель не способна эффективно обучиться, что демонстрируют полученные крайне низкие метрики. Это подчеркивает критическую важность использования знаний, полученных на больших датасетах.\n",
        "\n",
        "### 4.f. Добавление техник из улучшенного бейзлайна (пункт 3c) к \"кастомной\" модели\n",
        "В пункте 3с мы определили улучшенный бейзлайн, используя модель `yolov8s.pt` (более крупная архитектура) и увеличенное количество эпох. Попробуем применить аналогичный подход к обучению \"с нуля\": будем использовать архитектуру `yolov8s.yaml` и такое же количество эпох, как в пункте 3d.\n",
        "\n",
        "Это означает, что мы будем обучать более крупную модель **с нуля**.\n",
        "\n",
        "### 4.g. Обучение \"кастомной\" модели (yolov8s с нуля) с техниками из улучшенного бейзлайна\n",
        "\n"
      ],
      "metadata": {
        "id": "_27dj2lbC4SP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Параметры для обучения \"кастомной улучшенной\" модели (yolov8s.yaml с нуля)\n",
        "custom_imp_model_yaml = 'yolov8s.yaml' # Более крупная архитектура\n",
        "custom_imp_epochs = improved_epochs # То же количество эпох, что и в п.3.d\n",
        "custom_imp_imgsz = improved_imgsz # Тот же размер изображения\n",
        "custom_imp_project_name = 'coco128_custom_imp_scratch'\n",
        "custom_imp_experiment_name = 'yolov8s_from_scratch_imp_run'\n",
        "\n",
        "# Другие параметры (аугментации, lr0 и т.д.) из улучшенного бейзлайна пункта 3\n",
        "# также могут быть применены здесь, если они были явно заданы там.\n",
        "# В нашем примере из п.3 мы в основном меняли модель и эпохи.\n",
        "# model_improved.train(... mosaic=0.8 ...)\n",
        "\n",
        "print(f\"Обучение 'кастомной улучшенной' модели (с нуля): {custom_imp_model_yaml}\")\n",
        "print(f\"Датасет: {dataset_yaml}\")\n",
        "print(f\"Количество эпох: {custom_imp_epochs}\")\n",
        "print(f\"Размер изображения: {custom_imp_imgsz}\")\n",
        "\n",
        "# Создаем модель\n",
        "model_custom_imp_scratch = YOLO(custom_imp_model_yaml)\n",
        "\n",
        "try:\n",
        "    history_custom_imp_scratch = model_custom_imp_scratch.train(\n",
        "        data=dataset_yaml,\n",
        "        epochs=custom_imp_epochs,\n",
        "        imgsz=custom_imp_imgsz,\n",
        "        project=custom_imp_project_name,\n",
        "        name=custom_imp_experiment_name,\n",
        "        exist_ok=True,\n",
        "        patience=10 # Можно оставить или адаптировать\n",
        "        # mosaic=0.8, # Если такой параметр был в улучшенном бейзлайне п.3\n",
        "    )\n",
        "    print(\"Обучение 'кастомной улучшенной' модели (с нуля) завершено.\")\n",
        "    custom_imp_scratch_weights_path = os.path.join(custom_imp_project_name, custom_imp_experiment_name, 'weights', 'best.pt')\n",
        "    print(f\"Лучшие веса сохранены в: {custom_imp_scratch_weights_path}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Ошибка во время обучения 'кастомной улучшенной' модели (с нуля): {e}\")\n",
        "    history_custom_imp_scratch = None\n",
        "    custom_imp_scratch_weights_path = None\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klc-CAy5D4Ro",
        "outputId": "1073d424-9f09-45f7-c8c7-f4256f6b75c6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обучение 'кастомной улучшенной' модели (с нуля): yolov8s.yaml\n",
            "Датасет: coco128.yaml\n",
            "Количество эпох: 40\n",
            "Размер изображения: 640\n",
            "Ultralytics 8.3.139 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=coco128.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=40, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.yaml, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8s_from_scratch_imp_run, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=coco128_custom_imp_scratch, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=coco128_custom_imp_scratch/yolov8s_from_scratch_imp_run, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2147008  ultralytics.nn.modules.head.Detect           [80, [128, 256, 512]]         \n",
            "YOLOv8s summary: 129 layers, 11,166,560 parameters, 11,166,544 gradients, 28.8 GFLOPs\n",
            "\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1308.1±389.6 MB/s, size: 50.9 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|██████████| 128/128 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 385.3±144.8 MB/s, size: 52.5 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|██████████| 128/128 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to coco128_custom_imp_scratch/yolov8s_from_scratch_imp_run/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mcoco128_custom_imp_scratch/yolov8s_from_scratch_imp_run\u001b[0m\n",
            "Starting training for 40 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/40      4.28G      3.471      5.764      4.255        172        640: 100%|██████████| 8/8 [00:03<00:00,  2.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  4.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/40      5.27G      3.547      5.757      4.259        231        640: 100%|██████████| 8/8 [00:02<00:00,  3.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/40      5.31G      3.519      5.738      4.245        192        640: 100%|██████████| 8/8 [00:02<00:00,  3.37it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/40      5.34G      3.549      5.736      4.241        215        640: 100%|██████████| 8/8 [00:02<00:00,  3.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/40      5.34G      3.513      5.706      4.261        236        640: 100%|██████████| 8/8 [00:02<00:00,  3.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/40      5.34G      3.579      5.702      4.256        253        640: 100%|██████████| 8/8 [00:02<00:00,  3.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/40      5.38G      3.565      5.699      4.217        282        640: 100%|██████████| 8/8 [00:02<00:00,  3.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  4.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/40      5.38G      3.534      5.685      4.219        192        640: 100%|██████████| 8/8 [00:02<00:00,  2.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/40      5.42G      3.515      5.697      4.226        180        640: 100%|██████████| 8/8 [00:02<00:00,  3.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  4.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/40      5.42G      3.609      5.648      4.204        180        640: 100%|██████████| 8/8 [00:02<00:00,  3.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/40      5.42G      3.588      5.629      4.202        263        640: 100%|██████████| 8/8 [00:02<00:00,  3.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  4.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/40      5.42G      3.659      5.649      4.187        176        640: 100%|██████████| 8/8 [00:02<00:00,  3.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  4.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/40      5.42G      3.662      5.613      4.183        251        640: 100%|██████████| 8/8 [00:02<00:00,  3.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/40      5.42G      3.541      5.606      4.181        208        640: 100%|██████████| 8/8 [00:02<00:00,  3.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  4.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/40      5.42G      3.615      5.589      4.177        251        640: 100%|██████████| 8/8 [00:02<00:00,  3.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/40      5.42G      3.637      5.594      4.169        189        640: 100%|██████████| 8/8 [00:02<00:00,  3.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/40      5.42G      3.521      5.566      4.159        184        640: 100%|██████████| 8/8 [00:02<00:00,  3.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  4.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/40      5.42G      3.602      5.584       4.16        208        640: 100%|██████████| 8/8 [00:02<00:00,  2.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/40      5.42G      3.558      5.518       4.14        169        640: 100%|██████████| 8/8 [00:02<00:00,  3.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929   8.55e-05    0.00166   8.25e-05   3.23e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/40      5.42G       3.64      5.484      4.138        185        640: 100%|██████████| 8/8 [00:02<00:00,  3.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929   8.73e-05    0.00177   6.78e-05   2.75e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/40      5.42G      3.606      5.446      4.126        317        640: 100%|██████████| 8/8 [00:02<00:00,  3.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929   0.000146       0.01    0.00137   0.000345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/40      5.42G      3.498      5.492      4.129        255        640: 100%|██████████| 8/8 [00:02<00:00,  3.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929   8.13e-05     0.0103   0.000942   0.000278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/40      5.42G      3.598      5.437      4.115        227        640: 100%|██████████| 8/8 [00:02<00:00,  3.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929    0.00359     0.0125    0.00352   0.000736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/40      5.42G      3.564      5.381      4.108        196        640: 100%|██████████| 8/8 [00:02<00:00,  3.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929     0.0098      0.017     0.0104    0.00229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/40      5.42G      3.624      5.363      4.105        244        640: 100%|██████████| 8/8 [00:02<00:00,  3.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929    0.00606     0.0183    0.00567    0.00141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/40      5.45G      3.582      5.378      4.099        228        640: 100%|██████████| 8/8 [00:02<00:00,  3.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929    0.00166     0.0193    0.00349   0.000681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/40      5.45G      3.564      5.305       4.08        202        640: 100%|██████████| 8/8 [00:02<00:00,  3.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.304    0.00764    0.00354   0.000626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/40      5.45G       3.49      5.344      4.091        229        640: 100%|██████████| 8/8 [00:02<00:00,  3.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.327    0.00282    0.00361   0.000808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/40      5.49G      3.556      5.318      4.076        169        640: 100%|██████████| 8/8 [00:02<00:00,  3.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.331    0.00265    0.00365   0.000749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/40      5.49G      3.508      5.313      4.072        201        640: 100%|██████████| 8/8 [00:02<00:00,  3.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.302    0.00282    0.00372   0.000705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      31/40      5.49G      3.502      5.412      4.029        101        640: 100%|██████████| 8/8 [00:04<00:00,  1.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.328    0.00282    0.00259   0.000665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      32/40      5.49G      3.552      5.416      4.038        104        640: 100%|██████████| 8/8 [00:02<00:00,  3.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.342    0.00438    0.00263   0.000701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      33/40      5.49G      3.446      5.363      4.029        128        640: 100%|██████████| 8/8 [00:02<00:00,  3.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  2.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.341    0.00438    0.00218   0.000552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      34/40      5.49G      3.489      5.421      4.033        100        640: 100%|██████████| 8/8 [00:02<00:00,  3.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:01<00:00,  3.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929      0.355    0.00438    0.00245   0.000734\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 10 epochs. Best results observed at epoch 24, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "34 epochs completed in 0.050 hours.\n",
            "Optimizer stripped from coco128_custom_imp_scratch/yolov8s_from_scratch_imp_run/weights/last.pt, 22.6MB\n",
            "Optimizer stripped from coco128_custom_imp_scratch/yolov8s_from_scratch_imp_run/weights/best.pt, 22.6MB\n",
            "\n",
            "Validating coco128_custom_imp_scratch/yolov8s_from_scratch_imp_run/weights/best.pt...\n",
            "Ultralytics 8.3.139 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLOv8s summary (fused): 72 layers, 11,156,544 parameters, 0 gradients, 28.6 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929     0.0098      0.017     0.0104    0.00229\n",
            "                person         61        254    0.00353       0.15    0.00242     0.0009\n",
            "               bicycle          3          6          0          0          0          0\n",
            "                   car         12         46          0          0          0          0\n",
            "            motorcycle          4          5          0          0          0          0\n",
            "              airplane          5          6          0          0          0          0\n",
            "                   bus          5          7        0.5      0.143      0.286     0.0857\n",
            "                 train          3          3          0          0          0          0\n",
            "                 truck          5         12          0          0          0          0\n",
            "                  boat          2          6          0          0          0          0\n",
            "         traffic light          4         14          0          0          0          0\n",
            "             stop sign          2          2          0          0          0          0\n",
            "                 bench          5          9          0          0          0          0\n",
            "                  bird          2         16          0          0          0          0\n",
            "                   cat          4          4          0          0          0          0\n",
            "                   dog          9          9     0.0476      0.111      0.136     0.0263\n",
            "                 horse          1          2          0          0          0          0\n",
            "              elephant          4         17          0          0          0          0\n",
            "                  bear          1          1          0          0          0          0\n",
            "                 zebra          2          4          0          0          0          0\n",
            "               giraffe          4          9          0          0          0          0\n",
            "              backpack          4          6          0          0          0          0\n",
            "              umbrella          4         18          0          0          0          0\n",
            "               handbag          9         19          0          0          0          0\n",
            "                   tie          6          7          0          0          0          0\n",
            "              suitcase          2          4          0          0          0          0\n",
            "               frisbee          5          5      0.143        0.2      0.253     0.0359\n",
            "                  skis          1          1          0          0          0          0\n",
            "             snowboard          2          7          0          0          0          0\n",
            "           sports ball          6          6          0          0          0          0\n",
            "                  kite          2         10          0          0          0          0\n",
            "          baseball bat          4          4          0          0          0          0\n",
            "        baseball glove          4          7          0          0          0          0\n",
            "            skateboard          3          5          0          0          0          0\n",
            "         tennis racket          5          7          0          0          0          0\n",
            "                bottle          6         18          0          0          0          0\n",
            "            wine glass          5         16          0          0          0          0\n",
            "                   cup         10         36          0          0          0          0\n",
            "                  fork          6          6          0          0          0          0\n",
            "                 knife          7         16          0          0          0          0\n",
            "                 spoon          5         22          0          0          0          0\n",
            "                  bowl          9         28          0          0          0          0\n",
            "                banana          1          1          0          0          0          0\n",
            "              sandwich          2          2          0          0          0          0\n",
            "                orange          1          4          0          0          0          0\n",
            "              broccoli          4         11          0          0          0          0\n",
            "                carrot          3         24          0          0          0          0\n",
            "               hot dog          1          2          0          0          0          0\n",
            "                 pizza          5          5    0.00168        0.6     0.0628     0.0141\n",
            "                 donut          2         14          0          0          0          0\n",
            "                  cake          4          4          0          0          0          0\n",
            "                 chair          9         35          0          0          0          0\n",
            "                 couch          5          6          0          0          0          0\n",
            "          potted plant          9         14          0          0          0          0\n",
            "                   bed          3          3          0          0          0          0\n",
            "          dining table         10         13          0          0          0          0\n",
            "                toilet          2          2          0          0          0          0\n",
            "                    tv          2          2          0          0          0          0\n",
            "                laptop          2          3          0          0          0          0\n",
            "                 mouse          2          2          0          0          0          0\n",
            "                remote          5          8          0          0          0          0\n",
            "            cell phone          5          8          0          0          0          0\n",
            "             microwave          3          3          0          0          0          0\n",
            "                  oven          5          5          0          0          0          0\n",
            "                  sink          4          6          0          0          0          0\n",
            "          refrigerator          5          5          0          0          0          0\n",
            "                  book          6         29          0          0          0          0\n",
            "                 clock          8          9          0          0          0          0\n",
            "                  vase          2          2          0          0          0          0\n",
            "              scissors          1          1          0          0          0          0\n",
            "            teddy bear          6         21          0          0          0          0\n",
            "            toothbrush          2          5          0          0          0          0\n",
            "Speed: 0.2ms preprocess, 6.2ms inference, 0.0ms loss, 5.0ms postprocess per image\n",
            "Results saved to \u001b[1mcoco128_custom_imp_scratch/yolov8s_from_scratch_imp_run\u001b[0m\n",
            "Обучение 'кастомной улучшенной' модели (с нуля) завершено.\n",
            "Лучшие веса сохранены в: coco128_custom_imp_scratch/yolov8s_from_scratch_imp_run/weights/best.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.h. Оценка качества \"кастомной улучшенной\" модели (yolov8s с нуля)\n"
      ],
      "metadata": {
        "id": "JyP8YsGYD9v2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if custom_imp_scratch_weights_path and os.path.exists(custom_imp_scratch_weights_path):\n",
        "    print(f\"Оценка 'кастомной улучшенной' модели (с нуля) с весами: {custom_imp_scratch_weights_path}\")\n",
        "    model_eval_custom_imp_scratch = YOLO(custom_imp_scratch_weights_path)\n",
        "\n",
        "    metrics_custom_imp_scratch = model_eval_custom_imp_scratch.val(\n",
        "        data=dataset_yaml,\n",
        "        imgsz=custom_imp_imgsz,\n",
        "        split='val',\n",
        "        project=custom_imp_project_name,\n",
        "        name=custom_imp_experiment_name + \"_eval\",\n",
        "        exist_ok=True\n",
        "    )\n",
        "\n",
        "    print(\"\\nРезультаты оценки 'кастомной улучшенной' модели (обученной с нуля):\")\n",
        "    if metrics_custom_imp_scratch:\n",
        "        print(f\"  Precision(B): {metrics_custom_imp_scratch.box.mp:.4f}\")\n",
        "        print(f\"  Recall(B): {metrics_custom_imp_scratch.box.mr:.4f}\")\n",
        "        print(f\"  mAP50(B): {metrics_custom_imp_scratch.box.map50:.4f}\")\n",
        "        print(f\"  mAP50-95(B): {metrics_custom_imp_scratch.box.map:.4f}\")\n",
        "\n",
        "        results_history['custom_imp_scratch'] = {\n",
        "            'model': custom_imp_model_yaml.split('.')[0] + \" (scratch, imp)\",\n",
        "            'weights': custom_imp_scratch_weights_path,\n",
        "            'precision': metrics_custom_imp_scratch.box.mp,\n",
        "            'recall': metrics_custom_imp_scratch.box.mr,\n",
        "            'mAP50': metrics_custom_imp_scratch.box.map50,\n",
        "            'mAP50-95': metrics_custom_imp_scratch.box.map\n",
        "        }\n",
        "    else:\n",
        "        print(\"Не удалось получить метрики для 'кастомной улучшенной' модели (с нуля).\")\n",
        "        results_history['custom_imp_scratch'] = {\n",
        "          'model': custom_imp_model_yaml.split('.')[0] + \" (scratch, imp)\",\n",
        "          'weights': \"N/A\",\n",
        "          'precision': 0, 'recall': 0, 'mAP50': 0, 'mAP50-95': 0\n",
        "        }\n",
        "else:\n",
        "    print(\"Файл с весами 'кастомной улучшенной' модели (с нуля) не найден. Оценка невозможна.\")\n",
        "    results_history['custom_imp_scratch'] = {\n",
        "          'model': custom_imp_model_yaml.split('.')[0] + \" (scratch, imp)\",\n",
        "          'weights': \"N/A\",\n",
        "          'precision': 0, 'recall': 0, 'mAP50': 0, 'mAP50-95': 0\n",
        "        }\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9gnaMd3D-hY",
        "outputId": "983857b4-e010-46d1-e378-25a7ae2a3186"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Оценка 'кастомной улучшенной' модели (с нуля) с весами: coco128_custom_imp_scratch/yolov8s_from_scratch_imp_run/weights/best.pt\n",
            "Ultralytics 8.3.139 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLOv8s summary (fused): 72 layers, 11,156,544 parameters, 0 gradients, 28.6 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1624.2±294.9 MB/s, size: 53.4 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|██████████| 128/128 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:02<00:00,  3.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929    0.00276     0.0149    0.00842    0.00176\n",
            "                person         61        254    0.00353      0.146    0.00239   0.000861\n",
            "               bicycle          3          6          0          0          0          0\n",
            "                   car         12         46          0          0          0          0\n",
            "            motorcycle          4          5          0          0          0          0\n",
            "              airplane          5          6          0          0          0          0\n",
            "                   bus          5          7          0          0          0          0\n",
            "                 train          3          3          0          0          0          0\n",
            "                 truck          5         12          0          0          0          0\n",
            "                  boat          2          6          0          0          0          0\n",
            "         traffic light          4         14          0          0          0          0\n",
            "             stop sign          2          2          0          0          0          0\n",
            "                 bench          5          9          0          0          0          0\n",
            "                  bird          2         16          0          0          0          0\n",
            "                   cat          4          4          0          0          0          0\n",
            "                   dog          9          9     0.0476      0.111      0.136     0.0263\n",
            "                 horse          1          2          0          0          0          0\n",
            "              elephant          4         17          0          0          0          0\n",
            "                  bear          1          1          0          0          0          0\n",
            "                 zebra          2          4          0          0          0          0\n",
            "               giraffe          4          9          0          0          0          0\n",
            "              backpack          4          6          0          0          0          0\n",
            "              umbrella          4         18          0          0          0          0\n",
            "               handbag          9         19          0          0          0          0\n",
            "                   tie          6          7          0          0          0          0\n",
            "              suitcase          2          4          0          0          0          0\n",
            "               frisbee          5          5      0.143        0.2      0.253     0.0359\n",
            "                  skis          1          1          0          0          0          0\n",
            "             snowboard          2          7          0          0          0          0\n",
            "           sports ball          6          6          0          0          0          0\n",
            "                  kite          2         10          0          0          0          0\n",
            "          baseball bat          4          4          0          0          0          0\n",
            "        baseball glove          4          7          0          0          0          0\n",
            "            skateboard          3          5          0          0          0          0\n",
            "         tennis racket          5          7          0          0          0          0\n",
            "                bottle          6         18          0          0          0          0\n",
            "            wine glass          5         16          0          0          0          0\n",
            "                   cup         10         36          0          0          0          0\n",
            "                  fork          6          6          0          0          0          0\n",
            "                 knife          7         16          0          0          0          0\n",
            "                 spoon          5         22          0          0          0          0\n",
            "                  bowl          9         28          0          0          0          0\n",
            "                banana          1          1          0          0          0          0\n",
            "              sandwich          2          2          0          0          0          0\n",
            "                orange          1          4          0          0          0          0\n",
            "              broccoli          4         11          0          0          0          0\n",
            "                carrot          3         24          0          0          0          0\n",
            "               hot dog          1          2          0          0          0          0\n",
            "                 pizza          5          5    0.00178        0.6      0.207     0.0622\n",
            "                 donut          2         14          0          0          0          0\n",
            "                  cake          4          4          0          0          0          0\n",
            "                 chair          9         35          0          0          0          0\n",
            "                 couch          5          6          0          0          0          0\n",
            "          potted plant          9         14          0          0          0          0\n",
            "                   bed          3          3          0          0          0          0\n",
            "          dining table         10         13          0          0          0          0\n",
            "                toilet          2          2          0          0          0          0\n",
            "                    tv          2          2          0          0          0          0\n",
            "                laptop          2          3          0          0          0          0\n",
            "                 mouse          2          2          0          0          0          0\n",
            "                remote          5          8          0          0          0          0\n",
            "            cell phone          5          8          0          0          0          0\n",
            "             microwave          3          3          0          0          0          0\n",
            "                  oven          5          5          0          0          0          0\n",
            "                  sink          4          6          0          0          0          0\n",
            "          refrigerator          5          5          0          0          0          0\n",
            "                  book          6         29          0          0          0          0\n",
            "                 clock          8          9          0          0          0          0\n",
            "                  vase          2          2          0          0          0          0\n",
            "              scissors          1          1          0          0          0          0\n",
            "            teddy bear          6         21          0          0          0          0\n",
            "            toothbrush          2          5          0          0          0          0\n",
            "Speed: 2.5ms preprocess, 7.6ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
            "Results saved to \u001b[1mcoco128_custom_imp_scratch/yolov8s_from_scratch_imp_run_eval\u001b[0m\n",
            "\n",
            "Результаты оценки 'кастомной улучшенной' модели (обученной с нуля):\n",
            "  Precision(B): 0.0028\n",
            "  Recall(B): 0.0149\n",
            "  mAP50(B): 0.0084\n",
            "  mAP50-95(B): 0.0018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.i. Сравнение результатов \"кастомной улучшенной\" модели (yolov8s с нуля) с результатами из пункта 3 (улучшенный бейзлайн, yolov8s fine-tune)\n"
      ],
      "metadata": {
        "id": "-72vsb-gECjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Сравнение результатов: Улучшенный Бейзлайн (fine-tune) vs. 'Кастомная Улучшенная' (scratch)\")\n",
        "print(\"----------------------------------------------------------------------------------------------------\")\n",
        "print(f\"{'Модель':<40} | {'Precision':<10} | {'Recall':<10} | {'mAP@.50':<10} | {'mAP@.50-.95':<12}\")\n",
        "print(\"----------------------------------------------------------------------------------------------------\")\n",
        "\n",
        "if 'improved' in results_history: # Это улучшенный бейзлайн из п.3 (yolov8s.pt fine-tune)\n",
        "    i = results_history['improved']\n",
        "    print(f\"{'YOLOv8s (Улучшенный, fine-tune)':<40} | {i['precision']:.4f}   | {i['recall']:.4f}   | {i['mAP50']:.4f}   | {i['mAP50-95']:.4f}\")\n",
        "else:\n",
        "    print(f\"{'YOLOv8s (Улучшенный, fine-tune)':<40} | N/A        | N/A        | N/A        | N/A\")\n",
        "\n",
        "if 'custom_imp_scratch' in results_history: # Это yolov8s.yaml обученный с нуля с \"улучшениями\"\n",
        "    cis = results_history['custom_imp_scratch']\n",
        "    print(f\"{'YOLOv8s (Кастом-Улучш, с нуля)':<40} | {cis['precision']:.4f}   | {cis['recall']:.4f}   | {cis['mAP50']:.4f}   | {cis['mAP50-95']:.4f}\")\n",
        "\n",
        "    if 'improved' in results_history and i['mAP50-95'] > 0:\n",
        "        print(\"----------------------------------------------------------------------------------------------------\")\n",
        "        print(\"Изменения 'кастом-улучш, с нуля' относительно 'улучшенного fine-tune':\")\n",
        "        precision_diff_cis_vs_i = (cis['precision'] - i['precision']) / i['precision'] * 100 if i['precision'] !=0 else float('inf')\n",
        "        recall_diff_cis_vs_i = (cis['recall'] - i['recall']) / i['recall'] * 100 if i['recall'] !=0 else float('inf')\n",
        "        map50_diff_cis_vs_i = (cis['mAP50'] - i['mAP50']) / i['mAP50'] * 100 if i['mAP50'] !=0 else float('inf')\n",
        "        map_total_diff_cis_vs_i = (cis['mAP50-95'] - i['mAP50-95']) / i['mAP50-95'] * 100 if i['mAP50-95'] !=0 else float('inf')\n",
        "\n",
        "        print(f\"  Δ Precision: {precision_diff_cis_vs_i:+.2f}%\")\n",
        "        print(f\"  Δ Recall: {recall_diff_cis_vs_i:+.2f}%\")\n",
        "        print(f\"  Δ mAP@.50: {map50_diff_cis_vs_i:+.2f}%\")\n",
        "        print(f\"  Δ mAP@.50-.95: {map_total_diff_cis_vs_i:+.2f}%\")\n",
        "\n",
        "else:\n",
        "    print(f\"{'YOLOv8s (Кастом-Улучш, с нуля)':<40} | N/A        | N/A        | N/A        | N/A\")\n",
        "\n",
        "print(\"----------------------------------------------------------------------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wdy2yGmdEE57",
        "outputId": "0aae9c10-a29d-450a-ed67-56a4377e77fa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Сравнение результатов: Улучшенный Бейзлайн (fine-tune) vs. 'Кастомная Улучшенная' (scratch)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Модель                                   | Precision  | Recall     | mAP@.50    | mAP@.50-.95 \n",
            "----------------------------------------------------------------------------------------------------\n",
            "YOLOv8s (Улучшенный, fine-tune)          | 0.9231   | 0.8415   | 0.9104   | 0.7671\n",
            "YOLOv8s (Кастом-Улучш, с нуля)           | 0.0028   | 0.0149   | 0.0084   | 0.0018\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Изменения 'кастом-улучш, с нуля' относительно 'улучшенного fine-tune':\n",
            "  Δ Precision: -99.70%\n",
            "  Δ Recall: -98.23%\n",
            "  Δ mAP@.50: -99.07%\n",
            "  Δ mAP@.50-.95: -99.77%\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.j. Выводы по сравнению \"кастомной улучшенной\" модели (с нуля) с улучшенным бейзлайном (fine-tune)\n",
        "\n",
        "*   **Улучшенный бейзлайн (fine-tune `yolov8s.pt`):** Модель `yolov8s`, дообученная на COCO128 с `40` эпохами (*предполагается на основе предыдущих данных, уточните, если ваше M отличалось*), показала mAP@0.5:0.95 = `0.7671`.\n",
        "*   **\"Кастомная улучшенная\" модель (train `yolov8s.yaml` from scratch):** Модель архитектуры `yolov8s`, обученная с нуля на COCO128 с `40` эпохами (*те же параметры, что и для улучшенного бейзлайна*), показала mAP@0.5:0.95 = `0.0018`.\n",
        "\n",
        "*   **Сравнение:**\n",
        "    *   Даже при использовании более крупной архитектуры (`yolov8s.yaml`) и тех же \"улучшенных\" параметров обучения (количество эпох), обучение с нуля все еще **катастрофически уступает** дообучению (fine-tuning) модели `yolov8s.pt`. Разница в mAP@0.5:0.95 составила `-99.77%` (падение с `0.7671` до `0.0018`).\n",
        "    *   Все остальные метрики (Precision, Recall, mAP@0.5) также показали крайне значительное падение (`-99.70%`, `-98.23%`, `-99.07%` соответственно).\n",
        "    *   Это **полностью подтверждает** предыдущий вывод о критической важности предварительного обучения, особенно для небольших датасетов. Увеличение размера архитектуры при обучении с нуля на малом наборе данных не компенсирует отсутствие знаний, полученных при pre-training на большом датасете. Модель без предварительного обучения не смогла извлечь полезные признаки даже с более сложной архитектурой.\n",
        "\n",
        "*   **Общий вывод:** Для небольших датасетов, таких как COCO128, использование предварительно обученных весов (fine-tuning) остается наиболее эффективной стратегией для достижения высокого качества моделей обнаружения объектов. Обучение \"с нуля\", даже с более крупными архитектурами и увеличенным числом эпох, **категорически не позволяет** достичь сколько-нибудь приемлемого уровня производительности без значительного увеличения объема данных или продолжительности обучения. Эксперименты с обучением \"с нуля\" наглядно демонстрируют ценность transfer learning и сложность обучения глубоких моделей на ограниченных данных.\n",
        "\n",
        "---\n",
        "\n",
        "## Общие выводы по лабораторной работе №8\n",
        "\n",
        "В ходе выполнения лабораторной работы были проведены исследования с моделями обнаружения объектов семейства YOLO (на примере Ultralytics YOLOv8) на датасете COCO128.\n",
        "\n",
        "1.  **Бейзлайн:** Была обучена базовая модель (`yolov8n.pt` fine-tune) с `25` эпохами (*N, уточните, если ваше значение отличалось*), которая показала результат mAP@0.5:0.95 = `0.6047`.\n",
        "2.  **Улучшение бейзлайна:** Путем использования более крупной модели `yolov8s.pt` и увеличения числа эпох до `40` (*M, уточните, если ваше значение отличалось*) удалось **значительно улучшить** качество, достигнув mAP@0.5:0.95 = `0.7671`, что на `+26.86%` **лучше** бейзлайна. Это подтвердило гипотезу о том, что выбор более сложной архитектуры и увеличение продолжительности обучения могут положительно сказаться на результате при дообучении.\n",
        "3.  **\"Кастомная\" имплементация (обучение с нуля):**\n",
        "    *   Обучение модели `yolov8n.yaml` с нуля показало mAP@0.5:0.95 = `0.0010`, что значительно (на `99.83%`) **хуже** чем fine-tuning (`yolov8n.pt`). Это подчеркивает критическую важность transfer learning для малых датасетов.\n",
        "    *   Обучение более крупной модели `yolov8s.yaml` с нуля с \"улучшенными\" параметрами (аналогично п.2) дало mAP@0.5:0.95 = `0.0018`. Этот результат **все еще катастрофически уступал** (на `99.77%`) fine-tuning модели `yolov8s.pt` (`0.7671`), что **дополнительно и неопровержимо подтверждает** выводы о подавляющем преимуществе fine-tuning на малых датасетах, даже при использовании более мощных архитектур для обучения с нуля.\n",
        "\n",
        "**Ключевые наблюдения:**\n",
        "*   **Transfer Learning (Fine-tuning):** Является абсолютно доминирующим и мощным инструментом, особенно при ограниченном объеме целевых данных как COCO128. Использование предобученных весов (`.pt` файлы) дает несравнимо лучший старт и приводит к на порядки более высоким результатам по сравнению с обучением с нуля.\n",
        "*   **Размер модели и время обучения (при fine-tuning):** Более крупные модели (как `yolov8s` по сравнению с `yolov8n`) в сочетании с достаточным количеством эпох для дообучения могут дать значительный прирост качества.\n",
        "*   **Обучение с нуля на малых датасетах:** Для сложных задач, таких как обнаружение объектов, и современных глубоких архитектур, обучение с нуля на датасетах размером с COCO128 практически не приводит к формированию работоспособной модели, независимо от размера архитектуры (в разумных пределах) или количества эпох, сопоставимых с fine-tuning.\n",
        "*   **Датасет:** COCO128 удобен для быстрых экспериментов и демонстрации основных принципов, но его малый размер делает результаты обучения с нуля нерепрезентативными для реальных задач, где такие модели не смогли бы выучить общие признаки.\n",
        "\n",
        "**Практическая значимость:** Данная работа наглядно демонстрирует стандартный пайплайн работы с моделями обнаружения объектов и критическую важность стратегии transfer learning (fine-tuning) при работе с ограниченными наборами данных. Понимание того, что попытки обучить сложные модели \"с нуля\" на малых данных скорее всего обречены на неудачу, экономит время и ресурсы, направляя усилия на правильную адаптацию существующих мощных предобученных моделей."
      ],
      "metadata": {
        "id": "-DZ9g2ThEG-p"
      }
    }
  ]
}